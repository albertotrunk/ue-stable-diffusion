torchvision-0.13.1.dist-info/INSTALLER,sha256=zuuue4knoyJ-UwPPXg8fezS7VCrXJQrAP7zeNuwvFQg,4
torchvision-0.13.1.dist-info/LICENSE,,
torchvision-0.13.1.dist-info/METADATA,,
torchvision-0.13.1.dist-info/RECORD,,
torchvision-0.13.1.dist-info/REQUESTED,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
torchvision-0.13.1.dist-info/WHEEL,,
torchvision-0.13.1.dist-info/top_level.txt,,
torchvision-0.13.1.dist-info\LICENSE,sha256=wGNj-dM2J9xRc7E1IkRMyF-7Rzn2PhbUWH1cChZbWx4,1546
torchvision-0.13.1.dist-info\METADATA,sha256=NuM4_GQbzkU1mAybD7iklzh3mLYWdMHcuFHFDYB77_4,10761
torchvision-0.13.1.dist-info\RECORD,,
torchvision-0.13.1.dist-info\WHEEL,sha256=fVcVlLzi8CGi_Ul8vjMdn8gER25dn5GBg9E6k9z41-Y,100
torchvision-0.13.1.dist-info\top_level.txt,sha256=ucJZoaluBW9BGYT4TuCE6zoZY_JuSP30wbDh-IRpxUU,12
torchvision/_C.pyd,,
torchvision/__init__.py,,
torchvision/__pycache__/__init__.cpython-39.pyc,,
torchvision/__pycache__/_internally_replaced_utils.cpython-39.pyc,,
torchvision/__pycache__/_utils.cpython-39.pyc,,
torchvision/__pycache__/extension.cpython-39.pyc,,
torchvision/__pycache__/utils.cpython-39.pyc,,
torchvision/__pycache__/version.cpython-39.pyc,,
torchvision/_internally_replaced_utils.py,,
torchvision/_utils.py,,
torchvision/datasets/__init__.py,,
torchvision/datasets/__pycache__/__init__.cpython-39.pyc,,
torchvision/datasets/__pycache__/_optical_flow.cpython-39.pyc,,
torchvision/datasets/__pycache__/caltech.cpython-39.pyc,,
torchvision/datasets/__pycache__/celeba.cpython-39.pyc,,
torchvision/datasets/__pycache__/cifar.cpython-39.pyc,,
torchvision/datasets/__pycache__/cityscapes.cpython-39.pyc,,
torchvision/datasets/__pycache__/clevr.cpython-39.pyc,,
torchvision/datasets/__pycache__/coco.cpython-39.pyc,,
torchvision/datasets/__pycache__/country211.cpython-39.pyc,,
torchvision/datasets/__pycache__/dtd.cpython-39.pyc,,
torchvision/datasets/__pycache__/eurosat.cpython-39.pyc,,
torchvision/datasets/__pycache__/fakedata.cpython-39.pyc,,
torchvision/datasets/__pycache__/fer2013.cpython-39.pyc,,
torchvision/datasets/__pycache__/fgvc_aircraft.cpython-39.pyc,,
torchvision/datasets/__pycache__/flickr.cpython-39.pyc,,
torchvision/datasets/__pycache__/flowers102.cpython-39.pyc,,
torchvision/datasets/__pycache__/folder.cpython-39.pyc,,
torchvision/datasets/__pycache__/food101.cpython-39.pyc,,
torchvision/datasets/__pycache__/gtsrb.cpython-39.pyc,,
torchvision/datasets/__pycache__/hmdb51.cpython-39.pyc,,
torchvision/datasets/__pycache__/imagenet.cpython-39.pyc,,
torchvision/datasets/__pycache__/inaturalist.cpython-39.pyc,,
torchvision/datasets/__pycache__/kinetics.cpython-39.pyc,,
torchvision/datasets/__pycache__/kitti.cpython-39.pyc,,
torchvision/datasets/__pycache__/lfw.cpython-39.pyc,,
torchvision/datasets/__pycache__/lsun.cpython-39.pyc,,
torchvision/datasets/__pycache__/mnist.cpython-39.pyc,,
torchvision/datasets/__pycache__/omniglot.cpython-39.pyc,,
torchvision/datasets/__pycache__/oxford_iiit_pet.cpython-39.pyc,,
torchvision/datasets/__pycache__/pcam.cpython-39.pyc,,
torchvision/datasets/__pycache__/phototour.cpython-39.pyc,,
torchvision/datasets/__pycache__/places365.cpython-39.pyc,,
torchvision/datasets/__pycache__/rendered_sst2.cpython-39.pyc,,
torchvision/datasets/__pycache__/sbd.cpython-39.pyc,,
torchvision/datasets/__pycache__/sbu.cpython-39.pyc,,
torchvision/datasets/__pycache__/semeion.cpython-39.pyc,,
torchvision/datasets/__pycache__/stanford_cars.cpython-39.pyc,,
torchvision/datasets/__pycache__/stl10.cpython-39.pyc,,
torchvision/datasets/__pycache__/sun397.cpython-39.pyc,,
torchvision/datasets/__pycache__/svhn.cpython-39.pyc,,
torchvision/datasets/__pycache__/ucf101.cpython-39.pyc,,
torchvision/datasets/__pycache__/usps.cpython-39.pyc,,
torchvision/datasets/__pycache__/utils.cpython-39.pyc,,
torchvision/datasets/__pycache__/video_utils.cpython-39.pyc,,
torchvision/datasets/__pycache__/vision.cpython-39.pyc,,
torchvision/datasets/__pycache__/voc.cpython-39.pyc,,
torchvision/datasets/__pycache__/widerface.cpython-39.pyc,,
torchvision/datasets/_optical_flow.py,,
torchvision/datasets/caltech.py,,
torchvision/datasets/celeba.py,,
torchvision/datasets/cifar.py,,
torchvision/datasets/cityscapes.py,,
torchvision/datasets/clevr.py,,
torchvision/datasets/coco.py,,
torchvision/datasets/country211.py,,
torchvision/datasets/dtd.py,,
torchvision/datasets/eurosat.py,,
torchvision/datasets/fakedata.py,,
torchvision/datasets/fer2013.py,,
torchvision/datasets/fgvc_aircraft.py,,
torchvision/datasets/flickr.py,,
torchvision/datasets/flowers102.py,,
torchvision/datasets/folder.py,,
torchvision/datasets/food101.py,,
torchvision/datasets/gtsrb.py,,
torchvision/datasets/hmdb51.py,,
torchvision/datasets/imagenet.py,,
torchvision/datasets/inaturalist.py,,
torchvision/datasets/kinetics.py,,
torchvision/datasets/kitti.py,,
torchvision/datasets/lfw.py,,
torchvision/datasets/lsun.py,,
torchvision/datasets/mnist.py,,
torchvision/datasets/omniglot.py,,
torchvision/datasets/oxford_iiit_pet.py,,
torchvision/datasets/pcam.py,,
torchvision/datasets/phototour.py,,
torchvision/datasets/places365.py,,
torchvision/datasets/rendered_sst2.py,,
torchvision/datasets/samplers/__init__.py,,
torchvision/datasets/samplers/__pycache__/__init__.cpython-39.pyc,,
torchvision/datasets/samplers/__pycache__/clip_sampler.cpython-39.pyc,,
torchvision/datasets/samplers/clip_sampler.py,,
torchvision/datasets/sbd.py,,
torchvision/datasets/sbu.py,,
torchvision/datasets/semeion.py,,
torchvision/datasets/stanford_cars.py,,
torchvision/datasets/stl10.py,,
torchvision/datasets/sun397.py,,
torchvision/datasets/svhn.py,,
torchvision/datasets/ucf101.py,,
torchvision/datasets/usps.py,,
torchvision/datasets/utils.py,,
torchvision/datasets/video_utils.py,,
torchvision/datasets/vision.py,,
torchvision/datasets/voc.py,,
torchvision/datasets/widerface.py,,
torchvision/extension.py,,
torchvision/image.pyd,,
torchvision/io/__init__.py,,
torchvision/io/__pycache__/__init__.cpython-39.pyc,,
torchvision/io/__pycache__/_load_gpu_decoder.cpython-39.pyc,,
torchvision/io/__pycache__/_video_opt.cpython-39.pyc,,
torchvision/io/__pycache__/image.cpython-39.pyc,,
torchvision/io/__pycache__/video.cpython-39.pyc,,
torchvision/io/__pycache__/video_reader.cpython-39.pyc,,
torchvision/io/_load_gpu_decoder.py,,
torchvision/io/_video_opt.py,,
torchvision/io/image.py,,
torchvision/io/video.py,,
torchvision/io/video_reader.py,,
torchvision/libjpeg.dll,,
torchvision/libpng16.dll,,
torchvision/models/__init__.py,,
torchvision/models/__pycache__/__init__.cpython-39.pyc,,
torchvision/models/__pycache__/_api.cpython-39.pyc,,
torchvision/models/__pycache__/_meta.cpython-39.pyc,,
torchvision/models/__pycache__/_utils.cpython-39.pyc,,
torchvision/models/__pycache__/alexnet.cpython-39.pyc,,
torchvision/models/__pycache__/convnext.cpython-39.pyc,,
torchvision/models/__pycache__/densenet.cpython-39.pyc,,
torchvision/models/__pycache__/efficientnet.cpython-39.pyc,,
torchvision/models/__pycache__/feature_extraction.cpython-39.pyc,,
torchvision/models/__pycache__/googlenet.cpython-39.pyc,,
torchvision/models/__pycache__/inception.cpython-39.pyc,,
torchvision/models/__pycache__/mnasnet.cpython-39.pyc,,
torchvision/models/__pycache__/mobilenet.cpython-39.pyc,,
torchvision/models/__pycache__/mobilenetv2.cpython-39.pyc,,
torchvision/models/__pycache__/mobilenetv3.cpython-39.pyc,,
torchvision/models/__pycache__/regnet.cpython-39.pyc,,
torchvision/models/__pycache__/resnet.cpython-39.pyc,,
torchvision/models/__pycache__/shufflenetv2.cpython-39.pyc,,
torchvision/models/__pycache__/squeezenet.cpython-39.pyc,,
torchvision/models/__pycache__/swin_transformer.cpython-39.pyc,,
torchvision/models/__pycache__/vgg.cpython-39.pyc,,
torchvision/models/__pycache__/vision_transformer.cpython-39.pyc,,
torchvision/models/_api.py,,
torchvision/models/_meta.py,,
torchvision/models/_utils.py,,
torchvision/models/alexnet.py,,
torchvision/models/convnext.py,,
torchvision/models/densenet.py,,
torchvision/models/detection/__init__.py,,
torchvision/models/detection/__pycache__/__init__.cpython-39.pyc,,
torchvision/models/detection/__pycache__/_utils.cpython-39.pyc,,
torchvision/models/detection/__pycache__/anchor_utils.cpython-39.pyc,,
torchvision/models/detection/__pycache__/backbone_utils.cpython-39.pyc,,
torchvision/models/detection/__pycache__/faster_rcnn.cpython-39.pyc,,
torchvision/models/detection/__pycache__/fcos.cpython-39.pyc,,
torchvision/models/detection/__pycache__/generalized_rcnn.cpython-39.pyc,,
torchvision/models/detection/__pycache__/image_list.cpython-39.pyc,,
torchvision/models/detection/__pycache__/keypoint_rcnn.cpython-39.pyc,,
torchvision/models/detection/__pycache__/mask_rcnn.cpython-39.pyc,,
torchvision/models/detection/__pycache__/retinanet.cpython-39.pyc,,
torchvision/models/detection/__pycache__/roi_heads.cpython-39.pyc,,
torchvision/models/detection/__pycache__/rpn.cpython-39.pyc,,
torchvision/models/detection/__pycache__/ssd.cpython-39.pyc,,
torchvision/models/detection/__pycache__/ssdlite.cpython-39.pyc,,
torchvision/models/detection/__pycache__/transform.cpython-39.pyc,,
torchvision/models/detection/_utils.py,,
torchvision/models/detection/anchor_utils.py,,
torchvision/models/detection/backbone_utils.py,,
torchvision/models/detection/faster_rcnn.py,,
torchvision/models/detection/fcos.py,,
torchvision/models/detection/generalized_rcnn.py,,
torchvision/models/detection/image_list.py,,
torchvision/models/detection/keypoint_rcnn.py,,
torchvision/models/detection/mask_rcnn.py,,
torchvision/models/detection/retinanet.py,,
torchvision/models/detection/roi_heads.py,,
torchvision/models/detection/rpn.py,,
torchvision/models/detection/ssd.py,,
torchvision/models/detection/ssdlite.py,,
torchvision/models/detection/transform.py,,
torchvision/models/efficientnet.py,,
torchvision/models/feature_extraction.py,,
torchvision/models/googlenet.py,,
torchvision/models/inception.py,,
torchvision/models/mnasnet.py,,
torchvision/models/mobilenet.py,,
torchvision/models/mobilenetv2.py,,
torchvision/models/mobilenetv3.py,,
torchvision/models/optical_flow/__init__.py,,
torchvision/models/optical_flow/__pycache__/__init__.cpython-39.pyc,,
torchvision/models/optical_flow/__pycache__/_utils.cpython-39.pyc,,
torchvision/models/optical_flow/__pycache__/raft.cpython-39.pyc,,
torchvision/models/optical_flow/_utils.py,,
torchvision/models/optical_flow/raft.py,,
torchvision/models/quantization/__init__.py,,
torchvision/models/quantization/__pycache__/__init__.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/googlenet.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/inception.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/mobilenet.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/mobilenetv2.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/mobilenetv3.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/resnet.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/shufflenetv2.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/utils.cpython-39.pyc,,
torchvision/models/quantization/googlenet.py,,
torchvision/models/quantization/inception.py,,
torchvision/models/quantization/mobilenet.py,,
torchvision/models/quantization/mobilenetv2.py,,
torchvision/models/quantization/mobilenetv3.py,,
torchvision/models/quantization/resnet.py,,
torchvision/models/quantization/shufflenetv2.py,,
torchvision/models/quantization/utils.py,,
torchvision/models/regnet.py,,
torchvision/models/resnet.py,,
torchvision/models/segmentation/__init__.py,,
torchvision/models/segmentation/__pycache__/__init__.cpython-39.pyc,,
torchvision/models/segmentation/__pycache__/_utils.cpython-39.pyc,,
torchvision/models/segmentation/__pycache__/deeplabv3.cpython-39.pyc,,
torchvision/models/segmentation/__pycache__/fcn.cpython-39.pyc,,
torchvision/models/segmentation/__pycache__/lraspp.cpython-39.pyc,,
torchvision/models/segmentation/__pycache__/segmentation.cpython-39.pyc,,
torchvision/models/segmentation/_utils.py,,
torchvision/models/segmentation/deeplabv3.py,,
torchvision/models/segmentation/fcn.py,,
torchvision/models/segmentation/lraspp.py,,
torchvision/models/segmentation/segmentation.py,,
torchvision/models/shufflenetv2.py,,
torchvision/models/squeezenet.py,,
torchvision/models/swin_transformer.py,,
torchvision/models/vgg.py,,
torchvision/models/video/__init__.py,,
torchvision/models/video/__pycache__/__init__.cpython-39.pyc,,
torchvision/models/video/__pycache__/resnet.cpython-39.pyc,,
torchvision/models/video/resnet.py,,
torchvision/models/vision_transformer.py,,
torchvision/ops/__init__.py,,
torchvision/ops/__pycache__/__init__.cpython-39.pyc,,
torchvision/ops/__pycache__/_box_convert.cpython-39.pyc,,
torchvision/ops/__pycache__/_register_onnx_ops.cpython-39.pyc,,
torchvision/ops/__pycache__/_utils.cpython-39.pyc,,
torchvision/ops/__pycache__/boxes.cpython-39.pyc,,
torchvision/ops/__pycache__/ciou_loss.cpython-39.pyc,,
torchvision/ops/__pycache__/deform_conv.cpython-39.pyc,,
torchvision/ops/__pycache__/diou_loss.cpython-39.pyc,,
torchvision/ops/__pycache__/drop_block.cpython-39.pyc,,
torchvision/ops/__pycache__/feature_pyramid_network.cpython-39.pyc,,
torchvision/ops/__pycache__/focal_loss.cpython-39.pyc,,
torchvision/ops/__pycache__/giou_loss.cpython-39.pyc,,
torchvision/ops/__pycache__/misc.cpython-39.pyc,,
torchvision/ops/__pycache__/poolers.cpython-39.pyc,,
torchvision/ops/__pycache__/ps_roi_align.cpython-39.pyc,,
torchvision/ops/__pycache__/ps_roi_pool.cpython-39.pyc,,
torchvision/ops/__pycache__/roi_align.cpython-39.pyc,,
torchvision/ops/__pycache__/roi_pool.cpython-39.pyc,,
torchvision/ops/__pycache__/stochastic_depth.cpython-39.pyc,,
torchvision/ops/_box_convert.py,,
torchvision/ops/_register_onnx_ops.py,,
torchvision/ops/_utils.py,,
torchvision/ops/boxes.py,,
torchvision/ops/ciou_loss.py,,
torchvision/ops/deform_conv.py,,
torchvision/ops/diou_loss.py,,
torchvision/ops/drop_block.py,,
torchvision/ops/feature_pyramid_network.py,,
torchvision/ops/focal_loss.py,,
torchvision/ops/giou_loss.py,,
torchvision/ops/misc.py,,
torchvision/ops/poolers.py,,
torchvision/ops/ps_roi_align.py,,
torchvision/ops/ps_roi_pool.py,,
torchvision/ops/roi_align.py,,
torchvision/ops/roi_pool.py,,
torchvision/ops/stochastic_depth.py,,
torchvision/transforms/__init__.py,,
torchvision/transforms/__pycache__/__init__.cpython-39.pyc,,
torchvision/transforms/__pycache__/_functional_video.cpython-39.pyc,,
torchvision/transforms/__pycache__/_pil_constants.cpython-39.pyc,,
torchvision/transforms/__pycache__/_presets.cpython-39.pyc,,
torchvision/transforms/__pycache__/_transforms_video.cpython-39.pyc,,
torchvision/transforms/__pycache__/autoaugment.cpython-39.pyc,,
torchvision/transforms/__pycache__/functional.cpython-39.pyc,,
torchvision/transforms/__pycache__/functional_pil.cpython-39.pyc,,
torchvision/transforms/__pycache__/functional_tensor.cpython-39.pyc,,
torchvision/transforms/__pycache__/transforms.cpython-39.pyc,,
torchvision/transforms/_functional_video.py,,
torchvision/transforms/_pil_constants.py,,
torchvision/transforms/_presets.py,,
torchvision/transforms/_transforms_video.py,,
torchvision/transforms/autoaugment.py,,
torchvision/transforms/functional.py,,
torchvision/transforms/functional_pil.py,,
torchvision/transforms/functional_tensor.py,,
torchvision/transforms/transforms.py,,
torchvision/utils.py,,
torchvision/version.py,,
torchvision/zlib.dll,,
torchvision\_C.pyd,sha256=5lpYKuf5stFtpOskVpV065anaGO-mVDJ5pJN72u7aY4,536064
torchvision\__init__.py,sha256=n4hjKSG4nxA5ggSOgvCQYM59mbECE_sP6__bBIxR7OM,3121
torchvision\_internally_replaced_utils.py,sha256=oas5PoFR4LlsQAe4-cHj-FNsehe-deWD4AMwq4Y672U,1801
torchvision\_utils.py,sha256=x_w76GNeiH_wP2xFZ1zFZY6cVUI1axUcqa1-Ikr32aE,966
torchvision\datasets\__init__.py,sha256=DVyXgYVKw8Skukf3FSAcxCOhQDEhcqBF33E47wMwO-o,2662
torchvision\datasets\_optical_flow.py,sha256=-Ayi05K8-m6fFITi4zq7J6GIHoX9_iK-Cca8sM7BP7Y,19832
torchvision\datasets\caltech.py,sha256=_QIstaH3Feczav9UNv8YIroYHku3bJfbOMd70w0ZdKc,8975
torchvision\datasets\celeba.py,sha256=Ti7mf0eVSwPE_Z32B_QQhCynj6nKurep1MBWUi4QT44,8486
torchvision\datasets\cifar.py,sha256=ztgzxlIjmlKDkw6IilircHAD7S2jQMeonApq9hpmwsg,6020
torchvision\datasets\cityscapes.py,sha256=P82nKEmVfWIz-82GamhN9h7HUtGsu7oldALIOzy8WFA,10458
torchvision\datasets\clevr.py,sha256=qkxuuAa-JLc4KhxV-Yi2Uz83e_67HEjAqPNE_0zdhHw,3504
torchvision\datasets\coco.py,sha256=HihmSQdxOamtCbnHTOZFT9xsAWP5JKCVPa6Cw0-YoFA,4076
torchvision\datasets\country211.py,sha256=JLbKNAFVntzqlL4f3-26tsWlMxV6vNzT4mMz4_KY5i0,2466
torchvision\datasets\dtd.py,sha256=PCR0PzI88tStHIQ8sS0qBaqaGlmNPGtPI7ngFvk1JL4,4039
torchvision\datasets\eurosat.py,sha256=qTI24oTjJVXlfs5VHjvjC_3If9s9joobS1X7mbxswII,2111
torchvision\datasets\fakedata.py,sha256=eEiZFwVkcd0Zo-eps8AMRUkUpGKj9eQDZ6hoDxqsln0,2548
torchvision\datasets\fer2013.py,sha256=UNVXG2b0S0ZlAQn9Qr7cRyD3A4iEnW21gFpqhKf2KR4,2837
torchvision\datasets\fgvc_aircraft.py,sha256=RjJq2qiV2kKx84vZunk_asLdhi_BYU8cxT0QxJbQ7Ps,4675
torchvision\datasets\flickr.py,sha256=2MUvshyI3BfmEHja9yao_Fq5pqK9A_mXxxjvf4o3Sb0,5505
torchvision\datasets\flowers102.py,sha256=EGKY1w-92MymepzRYAV60NQ6xWocYgTzsl0gJJkwWtQ,4714
torchvision\datasets\folder.py,sha256=18bexIfkBp80cT88Pkkn5-fiYloBNZovykUXWFC9kKg,12246
torchvision\datasets\food101.py,sha256=deklWkwRS_tRq3JVZT_aRqs0xFtxiEw7Ay6j3Ch9bYg,3806
torchvision\datasets\gtsrb.py,sha256=3MpXIXkf9NiOa3Km75dRbjlx_uUqYtt-sQIGNKzT8gE,3845
torchvision\datasets\hmdb51.py,sha256=kvICMu3TgdoCd0TzPnuo-w71L2TbqFhCJteLwY5V-6I,6061
torchvision\datasets\imagenet.py,sha256=t8ScaPpMZSnaOqHyKEu7rl9OxcFX0ntbMcvvDw4QaSU,8342
torchvision\datasets\inaturalist.py,sha256=IxC96hg_xCx2n1reTUo99XtbGz2QGMNIHyA3AQImPwk,10348
torchvision\datasets\kinetics.py,sha256=RtszKdaX6fGgBAyrtn7Ka6uJOwZ3G9AiyN1qKCFgFZ4,13790
torchvision\datasets\kitti.py,sha256=yuX-fPZN7Rs08ZFWkOXNn9EXEng0oqO8H1rsEFcPyF0,5758
torchvision\datasets\lfw.py,sha256=RLLVKg5_MvNdPvSPELnS4uYp6LMdp8ZqODs1NDIa6M0,10537
torchvision\datasets\lsun.py,sha256=OD81y83LGyy-1zxDPGMZl4ddq3YzieGnw1iyACoESYE,5842
torchvision\datasets\mnist.py,sha256=w97NEPzXFrAMz5v3Ii9t41UxYZ7unIpwuxLDReVkKMI,21817
torchvision\datasets\omniglot.py,sha256=L5wZlBqNxTzLeRUfgN4eEiPgpSTDRF9xb7TrBmh_YBk,4193
torchvision\datasets\oxford_iiit_pet.py,sha256=5DoQJeGE7xKmXZTJrYX_YCS-B7pmubhs9ekLz-tzmjY,5197
torchvision\datasets\pcam.py,sha256=-xtECgRUKWbwAv1mAhSpSpS5ugIVY9vqUF-i3g5x80U,5245
torchvision\datasets\phototour.py,sha256=kiBA1S-06U0qWxwgG06lVFiqRpC12z-fzD_IOo1y8VA,8152
torchvision\datasets\places365.py,sha256=gdydOupGFXhkQBzq3zWi1DXZkejEUShyhwXCH3k8cvc,7371
torchvision\datasets\rendered_sst2.py,sha256=9XZgTir3Z4wdyYUF1VDeR0-xR4hyXI1Y0lyETA01Uj4,3643
torchvision\datasets\samplers\__init__.py,sha256=1FvVy3pTrv2oM9WN34eg0GFFJWPi7ImTG9pzESY7mFM,164
torchvision\datasets\samplers\clip_sampler.py,sha256=APrW5DB_5dOA2wsm-ul-iRmtNtBamm--UNQNTDQKgOs,6416
torchvision\datasets\sbd.py,sha256=2aN2hSuDt1JFzbI4pG9krP06fmtD_P2uCpty8G79B18,5325
torchvision\datasets\sbu.py,sha256=cbXwtiGJt7UxhHj7ymhPzGGNxyZS-d20ob30V27dvr0,4317
torchvision\datasets\semeion.py,sha256=P-FitWfYKqBHcghATdaX2qONxyQ-42wPyVR-fMEBrJI,3179
torchvision\datasets\stanford_cars.py,sha256=JcMB482ZVM0q3Xt3cYh_wOxpdwB7rP26QCihkjXUS2s,4964
torchvision\datasets\stl10.py,sha256=VO-28ofQe0pFInq-lY_9BBn7NR31kShCQ3NzVw9Ri_4,7470
torchvision\datasets\sun397.py,sha256=RO4HR7BFciUqtnw7hMoHXBcDPgNzIfxUwmmd3nWaBOc,2819
torchvision\datasets\svhn.py,sha256=GpW-quir870XVbNkHaJfa2JJ76BEQsLG1XJ_lniVhfA,4895
torchvision\datasets\ucf101.py,sha256=FDbgCkayDbmVnjODpSl5GvY5ihI0DIX0X8q5_7Vna-E,5602
torchvision\datasets\usps.py,sha256=PyFECpMSh0sMswf-rZFpzy-Uyopa2BLMEYKLJgGWBRE,3535
torchvision\datasets\utils.py,sha256=Zp9ByYTE9CfcZbpUPo8NVQG5pf2gD1YJXm0sfua6r8s,17805
torchvision\datasets\video_utils.py,sha256=jJzq3isaWlBDx5O2sj_-xoaGCwwZJFLzcdDoj8NUh_A,17407
torchvision\datasets\vision.py,sha256=4zp2Jbnm0xdlkmyKQd3q9NVL6TQIuqEY7EVDVYNjHCo,4281
torchvision\datasets\voc.py,sha256=ozSX_fxWxqMS3XnetqMYEQOvRcf1PjfXcRd1rK1fDNg,9580
torchvision\datasets\widerface.py,sha256=f_lLPPdZT9uM1924ClXF3uA2vO3ahkq-mQCzfNHsx7k,8278
torchvision\extension.py,sha256=BgZMnzzvuRw0hDufgWYIoldqcGIMMhzSDvqGQv3DZy4,3190
torchvision\image.pyd,sha256=CRfAISxPxLbl7EcNRJgz8EyHQKqGu-PWL_ZiOfUXshw,329728
torchvision\io\__init__.py,sha256=qMHfIqXPuGG9RHMqqP24Tx7v0XbCf4sUs3t27QzqQ70,1566
torchvision\io\_load_gpu_decoder.py,sha256=B3mPLXerJYXqiHv9FO2laRrGRlIkXii7CsD0J8J_SwU,182
torchvision\io\_video_opt.py,sha256=c-VD5X2pO14zrJWRBe1KA2wDb0TD5qNBWyXG5Pm0-K8,20234
torchvision\io\image.py,sha256=WDwQU-wouNndPdD74er1nljcGG0XjbR5XTDJrZPWfI8,9704
torchvision\io\video.py,sha256=pEBWZQ3kZ0AVzS5sAg3Fcp-M5caQ_IHTqzNe4NZ3WCo,15824
torchvision\io\video_reader.py,sha256=RLudgsaiIZvflkLvLQ_Q1TkUUcumaauHCs1vkSrewp8,6832
torchvision\libjpeg.dll,sha256=RqPZ7l_awQdV8gwNfq4uF6qso45ravyjVQPBb8IOd_I,229376
torchvision\libpng16.dll,sha256=rsn_UBkP5HAfaNf4cN4KKTxtp6fZ_eQfH_HTODlTN9s,192512
torchvision\models\__init__.py,sha256=r3MQYPTQnceVv1AdW4bZIFKkmbIgeTFLUDIDpJ-jPv8,555
torchvision\models\_api.py,sha256=jDd15RbD09YFFwqkg_7qY9oTboPSZnrWxsq3UDSySyk,5373
torchvision\models\_meta.py,sha256=2NSIICoq4MDzPZc00DlGJTgHOCwTBSObSTeRTh3E0tQ,30429
torchvision\models\_utils.py,sha256=mZY50pRgfNz5Ej9E44i_u_JRFoT5B3nBdSs0HOx7csQ,11119
torchvision\models\alexnet.py,sha256=Tz_xpnYh-ivuXkZFGDCHTTkhoxT1E_cCUmQTqYJO6ao,4716
torchvision\models\convnext.py,sha256=RGC-Vx3V-SdwbAQ1uUrPJxhV_ekHOFEeN2wKoo2KxG0,15373
torchvision\models\densenet.py,sha256=IhH8rgByg59N8E1va_HkUx7zs6qlNkn46W83VuTK2E0,17315
torchvision\models\detection\__init__.py,sha256=D4cs338Z4BQn5TgX2IKuJC9TD2rtw2svUDZlALR-lwI,175
torchvision\models\detection\_utils.py,sha256=8e_OWAgKYWWzXPj8tzENbnnUWRTX75LNjhjW85vXCDA,22599
torchvision\models\detection\anchor_utils.py,sha256=Rc0CnHl31QUcYxMR2_046yJ02CyfsThgZ8aqmaZpP8A,12090
torchvision\models\detection\backbone_utils.py,sha256=gSRG5NMZMvN05lN7Ud8QNXeYEmyoigA9h294m_8tCeI,10706
torchvision\models\detection\faster_rcnn.py,sha256=WlqKnHHL5U1TIlZ35V2VilbTsXQYM0Fo3IpYSi7vMuI,37473
torchvision\models\detection\fcos.py,sha256=F0czF7bgPDhkd-_mBXHj3GIfCPKZ7ofMvKVh5ReKzlA,35121
torchvision\models\detection\generalized_rcnn.py,sha256=8UhGUTq9S9-o9XHGinAoM8qzmgTOCl-sVo8mmVN7KL4,4861
torchvision\models\detection\image_list.py,sha256=IzFjxIaMdyFas1IHPBgAuBK3iYJOert5HzGurYJitNk,808
torchvision\models\detection\keypoint_rcnn.py,sha256=XwI_kM30RdsnLH_ltfIFuEWdRNYLgzYL5j1p9eQ4ltk,22481
torchvision\models\detection\mask_rcnn.py,sha256=5xhTq2iK0fof4C2mydOn3Xab2flZFKX1p-KKn0f7cU4,26925
torchvision\models\detection\retinanet.py,sha256=MsdCrq0tKIdaObHf0F026xUkZGqc3ZfZH1uBxn5b0cA,37830
torchvision\models\detection\roi_heads.py,sha256=uNfj_UGbwdwwbwdFF4S_Uf3L8HIWtJ8DJUEVUWkf0Jw,34698
torchvision\models\detection\rpn.py,sha256=bs-gUKQW9OuGv-OocpCbbsvyfI0Nb73I7XrM-MnLlqM,16209
torchvision\models\detection\ssd.py,sha256=sQGxdYWYanEdqZFMKuR-bEXAzpPvt1Yx-Wws7AVtdOs,30266
torchvision\models\detection\ssdlite.py,sha256=WOxF7iIjwIjY65zsT3kjk_CP0kV0_m52yYXtHunBFQI,13684
torchvision\models\detection\transform.py,sha256=kev3k21ZWAojfdzH3DdLy-AvASujJBG03_c21rEaexE,12148
torchvision\models\efficientnet.py,sha256=GvLhld002bdMH_SkLW766THAbcLRAsTkd1A5bnAVYIc,44021
torchvision\models\feature_extraction.py,sha256=uVe3iNQxTsueAcQ2M_0MK9htGxvHMb_5AfHyzHqSnu4,26152
torchvision\models\googlenet.py,sha256=wr11nWtGnFuic1Bfodhj5zwfYVKTxLczBcsZH6wSht8,13309
torchvision\models\inception.py,sha256=IywdOzzO61R6kMLbn8iL9l9348CeQBbOtJPFt3T9O9I,19502
torchvision\models\mnasnet.py,sha256=WXa_XsbZLzCH-_4GevyE20m3xldO6pJkMrgCM7P8EYQ,17667
torchvision\models\mobilenet.py,sha256=alrEJwktmXVcCphU8h2EAJZX0YdKfcz4tJEOdG2BXB8,217
torchvision\models\mobilenetv2.py,sha256=zFnCnrAYrTSLdIMH709h1Hq30uOXn7OJ3xza4CrJBCo,10738
torchvision\models\mobilenetv3.py,sha256=Rmhzta9sy4ZOY-QE7tInOUTmHc4L4wWOEDaYB2sheeM,17385
torchvision\models\optical_flow\__init__.py,sha256=uuRFAdvcDobdAbY2VmxEZ7_CLH_f5-JRkCSuJRkj4RY,21
torchvision\models\optical_flow\_utils.py,sha256=S1l1-IKzNcfAX6bA8Y946fLRLuOQxKzfGzAuvE3ZohM,1843
torchvision\models\optical_flow\raft.py,sha256=SfDR4a53A2E75QqKMZY_U4IyXSb0_sE6IKp-eU8WUdo,39158
torchvision\models\quantization\__init__.py,sha256=YOJmYqWQTfP5P2ypteZNKQOMW4VEB2WHJlYoSlSaL1Y,130
torchvision\models\quantization\googlenet.py,sha256=tyUJ-TfBFvZf6LzXiFOJ94efwqp2b8FjaDSag-_Wlko,8542
torchvision\models\quantization\inception.py,sha256=vopC4K9LnGvEIMnM0-HESpYyn0_NzwrAVfpHJhWUUGw,11488
torchvision\models\quantization\mobilenet.py,sha256=alrEJwktmXVcCphU8h2EAJZX0YdKfcz4tJEOdG2BXB8,217
torchvision\models\quantization\mobilenetv2.py,sha256=T4zQgzqEn92KgZ9cpwd6baQL_rpMtL4J5XP9LH-pzWk,6231
torchvision\models\quantization\mobilenetv3.py,sha256=5o4tfP3GrZw68WbSADbabGmxYgLatT5do4qJ_chcdxA,9648
torchvision\models\quantization\resnet.py,sha256=GEqdGt1EHT-7xRj81qtXliM5mGCyyvrr7qtxafdFEZA,18048
torchvision\models\quantization\shufflenetv2.py,sha256=eF0pVeeClVcdfwH8rFGVhysGG8Hr0IkEOIKjgzO5PkU,16735
torchvision\models\quantization\utils.py,sha256=Ij88l6toyO8MQi1w512Jt-yQ2Q9hK75-Z2SOjIzS6Zw,2109
torchvision\models\regnet.py,sha256=3h4TmXAa0UK4mByXaW_T77R9myy61TiB2tvpC_Ad9KE,64695
torchvision\models\resnet.py,sha256=DQEpltXD_lByNZollc4ipUsY4af4S4vNOglLLjj5Iw8,39285
torchvision\models\segmentation\__init__.py,sha256=TLL2SSmqE08HLiv_yyIWyIyrvf2xaOsZi0muDv_Y5Vc,69
torchvision\models\segmentation\_utils.py,sha256=zKNwODXwtTJikT-nq9-P0JmQJbbYm3a-7yi2TwHHyMQ,1234
torchvision\models\segmentation\deeplabv3.py,sha256=AUz6IqDLvz9H5c_b8AU4oJZajLPCXTZZPlED2OuUpsI,15421
torchvision\models\segmentation\fcn.py,sha256=NVwTcUfC3iwxr8tLzNEHMN1tu_S3oViWv0SR9yAiyas,9264
torchvision\models\segmentation\lraspp.py,sha256=hkJ3CmCj649Gz5hxv-zANp55mKazFyFZuqWbpqD1IsQ,7969
torchvision\models\segmentation\segmentation.py,sha256=51MTvUGiDaNXP8DTGN2FwyEjuFiWvRaigKmlH03rStM,311
torchvision\models\shufflenetv2.py,sha256=MDWSoZioLh2yNsOHglT3kYSMHNERyyqQqwoItp2tdw8,15878
torchvision\models\squeezenet.py,sha256=E-lDIexXDfgSi1Ygy2az6TiM8LDkstZrKgVWYnOniG0,9095
torchvision\models\swin_transformer.py,sha256=MTcnJHzRJ2oKGbH8Bm_P2ZxeTcT8bgAK_RQv5GO60hw,23912
torchvision\models\vgg.py,sha256=m7gqou_8nSAExmwe7JsgsniMEV2zfOBIH3sJ3YhB4i4,19575
torchvision\models\video\__init__.py,sha256=ZhPrHVNq45WUYG0zbGRcIGFmxCI7DXw87XIHwJxDZJ8,23
torchvision\models\video\resnet.py,sha256=EcE5V_ViFRFlqhdfx2OAszksV-kXvJR_KzJMLH-Z1rY,16868
torchvision\models\vision_transformer.py,sha256=WOGXEYJ4vruj4cwpmoKCnWyyAPxr4eulhfjxGTupJUY,32490
torchvision\ops\__init__.py,sha256=x0ZlcLMNdnb7ku01YRYO7SJkO3FF9Qbd0Wbi_J6FRi8,2001
torchvision\ops\_box_convert.py,sha256=U0iPo5GpCvo8FGcnPwYIYw0upoEM_omm1CknBT4L0mo,2489
torchvision\ops\_register_onnx_ops.py,sha256=3QbXn-qcw3QPxbDNC_1-d4o0S6VMoJB11B-tIS_MmOI,3005
torchvision\ops\_utils.py,sha256=xFrLnLhKDHiG2TN39tUWY-MJbLEPka6dkaVVJFAN7-8,3736
torchvision\ops\boxes.py,sha256=5_-3I0V6qX-yr0XVKCmgO3CWkaObUJmJaV9A3a3Er04,15914
torchvision\ops\ciou_loss.py,sha256=cjzI-piUnJfZvlCYutPlmQ7uMJm0QDWyC4oAyIhehUI,2568
torchvision\ops\deform_conv.py,sha256=HJOCXx088QJkPz442otgznhwaOkPBdbc9f5h0u1hPWk,7185
torchvision\ops\diou_loss.py,sha256=EZV5_MIstLZ9SMvbxCFHe3t0su9VTSR2ga1UmulVSLQ,3188
torchvision\ops\drop_block.py,sha256=iiabG23cBBptq5kGiBuMUJuu0ypZLMdGCv60hEnFJEk,6014
torchvision\ops\feature_pyramid_network.py,sha256=uSlUTDH-OaF4icBn3mtOr0JuMtVkuGs8HKtLo6WOxNg,8818
torchvision\ops\focal_loss.py,sha256=7v0XpcyRqEY8ti7I8VQQGtCmdM9l0VNLYRe7370CgQg,2051
torchvision\ops\giou_loss.py,sha256=NUAhZW5x0yG6D5p2Mi-8eXlk0epOOWR7Q4S7PGzq-vs,2506
torchvision\ops\misc.py,sha256=qIwrfdkE_HLcfuQEUM1viqoeiQpqmlPl8mHqQUivSTs,12976
torchvision\ops\poolers.py,sha256=0EyUfL6CEKROkA8WXQncIeOE-isu6tgBrkZSHoGXRYU,13109
torchvision\ops\ps_roi_align.py,sha256=zZZsiUnXKONwSIUHjlfJqSF7bDL-kA-fDiGiZoN4EcE,3682
torchvision\ops\ps_roi_pool.py,sha256=H_nzViQOpnls8hZ9a2mgnKacVqMQlb1E_s8pqAP-YBY,2907
torchvision\ops\roi_align.py,sha256=71Ikza-bVTzMbnRf14cro9YGvPUPcMMTP6bU3073C7k,4224
torchvision\ops\roi_pool.py,sha256=f6Xf8hrpR8VIzxU0fXU6yIYnDw5k8cGbNW9iE_Fo-mc,2961
torchvision\ops\stochastic_depth.py,sha256=9T4Zu_BaemKZafSmRwrPCVr5aaGH8tmzlsQAZO-1_-Y,2302
torchvision\transforms\__init__.py,sha256=WCNXTJUbJ1h7YaN9UfrBSvt--ST2PAV4sLICbTS-L5A,55
torchvision\transforms\_functional_video.py,sha256=K8fVl5kxbl1ecHGB6GwUPCvExEl59JTigypzWo6SDz8,3965
torchvision\transforms\_pil_constants.py,sha256=7RfwV0qVB0xSjOKKYGwl7TR2OwUdLilKO6TJI6G4M9A,843
torchvision\transforms\_presets.py,sha256=0esWZ7kmT2ve7fXpFQEqHJ2K0TF_JFom09NcK3PTVZw,8221
torchvision\transforms\_transforms_video.py,sha256=o5DcCk5aIOeF8XYLAPOn2MrMe7oVJcvCRcGq1N5Nrpk,5133
torchvision\transforms\autoaugment.py,sha256=VEtmSot3vUkRkJREoBxlsN7H_7FieN_FVEH6UU-f-8I,28858
torchvision\transforms\functional.py,sha256=nsoObpRoBGWaeMPphYdAJJVAe0upm2q891_JjHhNwMU,64835
torchvision\transforms\functional_pil.py,sha256=_wtAg4bP9xJrrtRXolH0paXNaLFagREX1VU2ZGlP0kk,13702
torchvision\transforms\functional_tensor.py,sha256=AX4dTj_KNr_SuI-FXdyfsBodQWTrQ2ZYHXGnp8wMDbA,35320
torchvision\transforms\transforms.py,sha256=9uno_l-snWkLyirll0MRw-pbGqyHt77BbqzVPPhKnKs,83640
torchvision\utils.py,sha256=Hx1w3C4XUSRivbCpVGyStYsLsh7bWgg1LgicbzMNsvw,22743
torchvision\version.py,sha256=jQdQ3l1_oQXbrMjVM3DYk3mON-XTjQOYpfPUp6ew-w4,206
torchvision\zlib.dll,sha256=w2RcUS-Gl90opVj4FvWJQLXTDEIu0uRsEHqhvjZbClU,87552
