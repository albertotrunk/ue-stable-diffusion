torchvision-0.15.0.dev20221026+cu117.dist-info/INSTALLER,sha256=zuuue4knoyJ-UwPPXg8fezS7VCrXJQrAP7zeNuwvFQg,4
torchvision-0.15.0.dev20221026+cu117.dist-info/LICENSE,,
torchvision-0.15.0.dev20221026+cu117.dist-info/METADATA,,
torchvision-0.15.0.dev20221026+cu117.dist-info/RECORD,,
torchvision-0.15.0.dev20221026+cu117.dist-info/REQUESTED,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
torchvision-0.15.0.dev20221026+cu117.dist-info/WHEEL,,
torchvision-0.15.0.dev20221026+cu117.dist-info/top_level.txt,,
torchvision-0.15.0.dev20221026+cu117.dist-info\LICENSE,sha256=wGNj-dM2J9xRc7E1IkRMyF-7Rzn2PhbUWH1cChZbWx4,1546
torchvision-0.15.0.dev20221026+cu117.dist-info\METADATA,sha256=MXj-wmnpOLhAOaq3xsGh1UXwHHa0auZ_-2MYiSvFlbo,11108
torchvision-0.15.0.dev20221026+cu117.dist-info\RECORD,,
torchvision-0.15.0.dev20221026+cu117.dist-info\WHEEL,sha256=fVcVlLzi8CGi_Ul8vjMdn8gER25dn5GBg9E6k9z41-Y,100
torchvision-0.15.0.dev20221026+cu117.dist-info\top_level.txt,sha256=ucJZoaluBW9BGYT4TuCE6zoZY_JuSP30wbDh-IRpxUU,12
torchvision/_C.pyd,,
torchvision/__init__.py,,
torchvision/__pycache__/__init__.cpython-39.pyc,,
torchvision/__pycache__/_internally_replaced_utils.cpython-39.pyc,,
torchvision/__pycache__/_utils.cpython-39.pyc,,
torchvision/__pycache__/extension.cpython-39.pyc,,
torchvision/__pycache__/utils.cpython-39.pyc,,
torchvision/__pycache__/version.cpython-39.pyc,,
torchvision/_internally_replaced_utils.py,,
torchvision/_utils.py,,
torchvision/cudart64_110.dll,,
torchvision/datasets/__init__.py,,
torchvision/datasets/__pycache__/__init__.cpython-39.pyc,,
torchvision/datasets/__pycache__/_optical_flow.cpython-39.pyc,,
torchvision/datasets/__pycache__/_stereo_matching.cpython-39.pyc,,
torchvision/datasets/__pycache__/caltech.cpython-39.pyc,,
torchvision/datasets/__pycache__/celeba.cpython-39.pyc,,
torchvision/datasets/__pycache__/cifar.cpython-39.pyc,,
torchvision/datasets/__pycache__/cityscapes.cpython-39.pyc,,
torchvision/datasets/__pycache__/clevr.cpython-39.pyc,,
torchvision/datasets/__pycache__/coco.cpython-39.pyc,,
torchvision/datasets/__pycache__/country211.cpython-39.pyc,,
torchvision/datasets/__pycache__/dtd.cpython-39.pyc,,
torchvision/datasets/__pycache__/eurosat.cpython-39.pyc,,
torchvision/datasets/__pycache__/fakedata.cpython-39.pyc,,
torchvision/datasets/__pycache__/fer2013.cpython-39.pyc,,
torchvision/datasets/__pycache__/fgvc_aircraft.cpython-39.pyc,,
torchvision/datasets/__pycache__/flickr.cpython-39.pyc,,
torchvision/datasets/__pycache__/flowers102.cpython-39.pyc,,
torchvision/datasets/__pycache__/folder.cpython-39.pyc,,
torchvision/datasets/__pycache__/food101.cpython-39.pyc,,
torchvision/datasets/__pycache__/gtsrb.cpython-39.pyc,,
torchvision/datasets/__pycache__/hmdb51.cpython-39.pyc,,
torchvision/datasets/__pycache__/imagenet.cpython-39.pyc,,
torchvision/datasets/__pycache__/inaturalist.cpython-39.pyc,,
torchvision/datasets/__pycache__/kinetics.cpython-39.pyc,,
torchvision/datasets/__pycache__/kitti.cpython-39.pyc,,
torchvision/datasets/__pycache__/lfw.cpython-39.pyc,,
torchvision/datasets/__pycache__/lsun.cpython-39.pyc,,
torchvision/datasets/__pycache__/mnist.cpython-39.pyc,,
torchvision/datasets/__pycache__/omniglot.cpython-39.pyc,,
torchvision/datasets/__pycache__/oxford_iiit_pet.cpython-39.pyc,,
torchvision/datasets/__pycache__/pcam.cpython-39.pyc,,
torchvision/datasets/__pycache__/phototour.cpython-39.pyc,,
torchvision/datasets/__pycache__/places365.cpython-39.pyc,,
torchvision/datasets/__pycache__/rendered_sst2.cpython-39.pyc,,
torchvision/datasets/__pycache__/sbd.cpython-39.pyc,,
torchvision/datasets/__pycache__/sbu.cpython-39.pyc,,
torchvision/datasets/__pycache__/semeion.cpython-39.pyc,,
torchvision/datasets/__pycache__/stanford_cars.cpython-39.pyc,,
torchvision/datasets/__pycache__/stl10.cpython-39.pyc,,
torchvision/datasets/__pycache__/sun397.cpython-39.pyc,,
torchvision/datasets/__pycache__/svhn.cpython-39.pyc,,
torchvision/datasets/__pycache__/ucf101.cpython-39.pyc,,
torchvision/datasets/__pycache__/usps.cpython-39.pyc,,
torchvision/datasets/__pycache__/utils.cpython-39.pyc,,
torchvision/datasets/__pycache__/video_utils.cpython-39.pyc,,
torchvision/datasets/__pycache__/vision.cpython-39.pyc,,
torchvision/datasets/__pycache__/voc.cpython-39.pyc,,
torchvision/datasets/__pycache__/widerface.cpython-39.pyc,,
torchvision/datasets/_optical_flow.py,,
torchvision/datasets/_stereo_matching.py,,
torchvision/datasets/caltech.py,,
torchvision/datasets/celeba.py,,
torchvision/datasets/cifar.py,,
torchvision/datasets/cityscapes.py,,
torchvision/datasets/clevr.py,,
torchvision/datasets/coco.py,,
torchvision/datasets/country211.py,,
torchvision/datasets/dtd.py,,
torchvision/datasets/eurosat.py,,
torchvision/datasets/fakedata.py,,
torchvision/datasets/fer2013.py,,
torchvision/datasets/fgvc_aircraft.py,,
torchvision/datasets/flickr.py,,
torchvision/datasets/flowers102.py,,
torchvision/datasets/folder.py,,
torchvision/datasets/food101.py,,
torchvision/datasets/gtsrb.py,,
torchvision/datasets/hmdb51.py,,
torchvision/datasets/imagenet.py,,
torchvision/datasets/inaturalist.py,,
torchvision/datasets/kinetics.py,,
torchvision/datasets/kitti.py,,
torchvision/datasets/lfw.py,,
torchvision/datasets/lsun.py,,
torchvision/datasets/mnist.py,,
torchvision/datasets/omniglot.py,,
torchvision/datasets/oxford_iiit_pet.py,,
torchvision/datasets/pcam.py,,
torchvision/datasets/phototour.py,,
torchvision/datasets/places365.py,,
torchvision/datasets/rendered_sst2.py,,
torchvision/datasets/samplers/__init__.py,,
torchvision/datasets/samplers/__pycache__/__init__.cpython-39.pyc,,
torchvision/datasets/samplers/__pycache__/clip_sampler.cpython-39.pyc,,
torchvision/datasets/samplers/clip_sampler.py,,
torchvision/datasets/sbd.py,,
torchvision/datasets/sbu.py,,
torchvision/datasets/semeion.py,,
torchvision/datasets/stanford_cars.py,,
torchvision/datasets/stl10.py,,
torchvision/datasets/sun397.py,,
torchvision/datasets/svhn.py,,
torchvision/datasets/ucf101.py,,
torchvision/datasets/usps.py,,
torchvision/datasets/utils.py,,
torchvision/datasets/video_utils.py,,
torchvision/datasets/vision.py,,
torchvision/datasets/voc.py,,
torchvision/datasets/widerface.py,,
torchvision/extension.py,,
torchvision/image.pyd,,
torchvision/io/__init__.py,,
torchvision/io/__pycache__/__init__.cpython-39.pyc,,
torchvision/io/__pycache__/_load_gpu_decoder.cpython-39.pyc,,
torchvision/io/__pycache__/_video_opt.cpython-39.pyc,,
torchvision/io/__pycache__/image.cpython-39.pyc,,
torchvision/io/__pycache__/video.cpython-39.pyc,,
torchvision/io/__pycache__/video_reader.cpython-39.pyc,,
torchvision/io/_load_gpu_decoder.py,,
torchvision/io/_video_opt.py,,
torchvision/io/image.py,,
torchvision/io/video.py,,
torchvision/io/video_reader.py,,
torchvision/libjpeg.dll,,
torchvision/libpng16.dll,,
torchvision/models/__init__.py,,
torchvision/models/__pycache__/__init__.cpython-39.pyc,,
torchvision/models/__pycache__/_api.cpython-39.pyc,,
torchvision/models/__pycache__/_meta.cpython-39.pyc,,
torchvision/models/__pycache__/_utils.cpython-39.pyc,,
torchvision/models/__pycache__/alexnet.cpython-39.pyc,,
torchvision/models/__pycache__/convnext.cpython-39.pyc,,
torchvision/models/__pycache__/densenet.cpython-39.pyc,,
torchvision/models/__pycache__/efficientnet.cpython-39.pyc,,
torchvision/models/__pycache__/feature_extraction.cpython-39.pyc,,
torchvision/models/__pycache__/googlenet.cpython-39.pyc,,
torchvision/models/__pycache__/inception.cpython-39.pyc,,
torchvision/models/__pycache__/maxvit.cpython-39.pyc,,
torchvision/models/__pycache__/mnasnet.cpython-39.pyc,,
torchvision/models/__pycache__/mobilenet.cpython-39.pyc,,
torchvision/models/__pycache__/mobilenetv2.cpython-39.pyc,,
torchvision/models/__pycache__/mobilenetv3.cpython-39.pyc,,
torchvision/models/__pycache__/regnet.cpython-39.pyc,,
torchvision/models/__pycache__/resnet.cpython-39.pyc,,
torchvision/models/__pycache__/shufflenetv2.cpython-39.pyc,,
torchvision/models/__pycache__/squeezenet.cpython-39.pyc,,
torchvision/models/__pycache__/swin_transformer.cpython-39.pyc,,
torchvision/models/__pycache__/vgg.cpython-39.pyc,,
torchvision/models/__pycache__/vision_transformer.cpython-39.pyc,,
torchvision/models/_api.py,,
torchvision/models/_meta.py,,
torchvision/models/_utils.py,,
torchvision/models/alexnet.py,,
torchvision/models/convnext.py,,
torchvision/models/densenet.py,,
torchvision/models/detection/__init__.py,,
torchvision/models/detection/__pycache__/__init__.cpython-39.pyc,,
torchvision/models/detection/__pycache__/_utils.cpython-39.pyc,,
torchvision/models/detection/__pycache__/anchor_utils.cpython-39.pyc,,
torchvision/models/detection/__pycache__/backbone_utils.cpython-39.pyc,,
torchvision/models/detection/__pycache__/faster_rcnn.cpython-39.pyc,,
torchvision/models/detection/__pycache__/fcos.cpython-39.pyc,,
torchvision/models/detection/__pycache__/generalized_rcnn.cpython-39.pyc,,
torchvision/models/detection/__pycache__/image_list.cpython-39.pyc,,
torchvision/models/detection/__pycache__/keypoint_rcnn.cpython-39.pyc,,
torchvision/models/detection/__pycache__/mask_rcnn.cpython-39.pyc,,
torchvision/models/detection/__pycache__/retinanet.cpython-39.pyc,,
torchvision/models/detection/__pycache__/roi_heads.cpython-39.pyc,,
torchvision/models/detection/__pycache__/rpn.cpython-39.pyc,,
torchvision/models/detection/__pycache__/ssd.cpython-39.pyc,,
torchvision/models/detection/__pycache__/ssdlite.cpython-39.pyc,,
torchvision/models/detection/__pycache__/transform.cpython-39.pyc,,
torchvision/models/detection/_utils.py,,
torchvision/models/detection/anchor_utils.py,,
torchvision/models/detection/backbone_utils.py,,
torchvision/models/detection/faster_rcnn.py,,
torchvision/models/detection/fcos.py,,
torchvision/models/detection/generalized_rcnn.py,,
torchvision/models/detection/image_list.py,,
torchvision/models/detection/keypoint_rcnn.py,,
torchvision/models/detection/mask_rcnn.py,,
torchvision/models/detection/retinanet.py,,
torchvision/models/detection/roi_heads.py,,
torchvision/models/detection/rpn.py,,
torchvision/models/detection/ssd.py,,
torchvision/models/detection/ssdlite.py,,
torchvision/models/detection/transform.py,,
torchvision/models/efficientnet.py,,
torchvision/models/feature_extraction.py,,
torchvision/models/googlenet.py,,
torchvision/models/inception.py,,
torchvision/models/maxvit.py,,
torchvision/models/mnasnet.py,,
torchvision/models/mobilenet.py,,
torchvision/models/mobilenetv2.py,,
torchvision/models/mobilenetv3.py,,
torchvision/models/optical_flow/__init__.py,,
torchvision/models/optical_flow/__pycache__/__init__.cpython-39.pyc,,
torchvision/models/optical_flow/__pycache__/_utils.cpython-39.pyc,,
torchvision/models/optical_flow/__pycache__/raft.cpython-39.pyc,,
torchvision/models/optical_flow/_utils.py,,
torchvision/models/optical_flow/raft.py,,
torchvision/models/quantization/__init__.py,,
torchvision/models/quantization/__pycache__/__init__.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/googlenet.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/inception.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/mobilenet.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/mobilenetv2.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/mobilenetv3.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/resnet.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/shufflenetv2.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/utils.cpython-39.pyc,,
torchvision/models/quantization/googlenet.py,,
torchvision/models/quantization/inception.py,,
torchvision/models/quantization/mobilenet.py,,
torchvision/models/quantization/mobilenetv2.py,,
torchvision/models/quantization/mobilenetv3.py,,
torchvision/models/quantization/resnet.py,,
torchvision/models/quantization/shufflenetv2.py,,
torchvision/models/quantization/utils.py,,
torchvision/models/regnet.py,,
torchvision/models/resnet.py,,
torchvision/models/segmentation/__init__.py,,
torchvision/models/segmentation/__pycache__/__init__.cpython-39.pyc,,
torchvision/models/segmentation/__pycache__/_utils.cpython-39.pyc,,
torchvision/models/segmentation/__pycache__/deeplabv3.cpython-39.pyc,,
torchvision/models/segmentation/__pycache__/fcn.cpython-39.pyc,,
torchvision/models/segmentation/__pycache__/lraspp.cpython-39.pyc,,
torchvision/models/segmentation/_utils.py,,
torchvision/models/segmentation/deeplabv3.py,,
torchvision/models/segmentation/fcn.py,,
torchvision/models/segmentation/lraspp.py,,
torchvision/models/shufflenetv2.py,,
torchvision/models/squeezenet.py,,
torchvision/models/swin_transformer.py,,
torchvision/models/vgg.py,,
torchvision/models/video/__init__.py,,
torchvision/models/video/__pycache__/__init__.cpython-39.pyc,,
torchvision/models/video/__pycache__/mvit.cpython-39.pyc,,
torchvision/models/video/__pycache__/resnet.cpython-39.pyc,,
torchvision/models/video/__pycache__/s3d.cpython-39.pyc,,
torchvision/models/video/mvit.py,,
torchvision/models/video/resnet.py,,
torchvision/models/video/s3d.py,,
torchvision/models/vision_transformer.py,,
torchvision/nvjpeg64_11.dll,,
torchvision/ops/__init__.py,,
torchvision/ops/__pycache__/__init__.cpython-39.pyc,,
torchvision/ops/__pycache__/_box_convert.cpython-39.pyc,,
torchvision/ops/__pycache__/_register_onnx_ops.cpython-39.pyc,,
torchvision/ops/__pycache__/_utils.cpython-39.pyc,,
torchvision/ops/__pycache__/boxes.cpython-39.pyc,,
torchvision/ops/__pycache__/ciou_loss.cpython-39.pyc,,
torchvision/ops/__pycache__/deform_conv.cpython-39.pyc,,
torchvision/ops/__pycache__/diou_loss.cpython-39.pyc,,
torchvision/ops/__pycache__/drop_block.cpython-39.pyc,,
torchvision/ops/__pycache__/feature_pyramid_network.cpython-39.pyc,,
torchvision/ops/__pycache__/focal_loss.cpython-39.pyc,,
torchvision/ops/__pycache__/giou_loss.cpython-39.pyc,,
torchvision/ops/__pycache__/misc.cpython-39.pyc,,
torchvision/ops/__pycache__/poolers.cpython-39.pyc,,
torchvision/ops/__pycache__/ps_roi_align.cpython-39.pyc,,
torchvision/ops/__pycache__/ps_roi_pool.cpython-39.pyc,,
torchvision/ops/__pycache__/roi_align.cpython-39.pyc,,
torchvision/ops/__pycache__/roi_pool.cpython-39.pyc,,
torchvision/ops/__pycache__/stochastic_depth.cpython-39.pyc,,
torchvision/ops/_box_convert.py,,
torchvision/ops/_register_onnx_ops.py,,
torchvision/ops/_utils.py,,
torchvision/ops/boxes.py,,
torchvision/ops/ciou_loss.py,,
torchvision/ops/deform_conv.py,,
torchvision/ops/diou_loss.py,,
torchvision/ops/drop_block.py,,
torchvision/ops/feature_pyramid_network.py,,
torchvision/ops/focal_loss.py,,
torchvision/ops/giou_loss.py,,
torchvision/ops/misc.py,,
torchvision/ops/poolers.py,,
torchvision/ops/ps_roi_align.py,,
torchvision/ops/ps_roi_pool.py,,
torchvision/ops/roi_align.py,,
torchvision/ops/roi_pool.py,,
torchvision/ops/stochastic_depth.py,,
torchvision/prototype/__init__.py,,
torchvision/prototype/__pycache__/__init__.cpython-39.pyc,,
torchvision/prototype/datasets/__init__.py,,
torchvision/prototype/datasets/__pycache__/__init__.cpython-39.pyc,,
torchvision/prototype/datasets/__pycache__/_api.cpython-39.pyc,,
torchvision/prototype/datasets/__pycache__/_folder.cpython-39.pyc,,
torchvision/prototype/datasets/__pycache__/_home.cpython-39.pyc,,
torchvision/prototype/datasets/__pycache__/benchmark.cpython-39.pyc,,
torchvision/prototype/datasets/__pycache__/generate_category_files.cpython-39.pyc,,
torchvision/prototype/datasets/_api.py,,
torchvision/prototype/datasets/_builtin/__init__.py,,
torchvision/prototype/datasets/_builtin/__pycache__/__init__.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/caltech.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/celeba.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/cifar.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/clevr.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/coco.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/country211.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/cub200.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/dtd.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/eurosat.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/fer2013.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/food101.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/gtsrb.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/imagenet.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/mnist.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/oxford_iiit_pet.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/pcam.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/sbd.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/semeion.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/stanford_cars.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/svhn.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/usps.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/voc.cpython-39.pyc,,
torchvision/prototype/datasets/_builtin/caltech.py,,
torchvision/prototype/datasets/_builtin/caltech101.categories,,
torchvision/prototype/datasets/_builtin/caltech256.categories,,
torchvision/prototype/datasets/_builtin/celeba.py,,
torchvision/prototype/datasets/_builtin/cifar.py,,
torchvision/prototype/datasets/_builtin/cifar10.categories,,
torchvision/prototype/datasets/_builtin/cifar100.categories,,
torchvision/prototype/datasets/_builtin/clevr.py,,
torchvision/prototype/datasets/_builtin/coco.categories,,
torchvision/prototype/datasets/_builtin/coco.py,,
torchvision/prototype/datasets/_builtin/country211.categories,,
torchvision/prototype/datasets/_builtin/country211.py,,
torchvision/prototype/datasets/_builtin/cub200.categories,,
torchvision/prototype/datasets/_builtin/cub200.py,,
torchvision/prototype/datasets/_builtin/dtd.categories,,
torchvision/prototype/datasets/_builtin/dtd.py,,
torchvision/prototype/datasets/_builtin/eurosat.py,,
torchvision/prototype/datasets/_builtin/fer2013.py,,
torchvision/prototype/datasets/_builtin/food101.categories,,
torchvision/prototype/datasets/_builtin/food101.py,,
torchvision/prototype/datasets/_builtin/gtsrb.py,,
torchvision/prototype/datasets/_builtin/imagenet.categories,,
torchvision/prototype/datasets/_builtin/imagenet.py,,
torchvision/prototype/datasets/_builtin/mnist.py,,
torchvision/prototype/datasets/_builtin/oxford-iiit-pet.categories,,
torchvision/prototype/datasets/_builtin/oxford_iiit_pet.py,,
torchvision/prototype/datasets/_builtin/pcam.py,,
torchvision/prototype/datasets/_builtin/sbd.categories,,
torchvision/prototype/datasets/_builtin/sbd.py,,
torchvision/prototype/datasets/_builtin/semeion.py,,
torchvision/prototype/datasets/_builtin/stanford-cars.categories,,
torchvision/prototype/datasets/_builtin/stanford_cars.py,,
torchvision/prototype/datasets/_builtin/svhn.py,,
torchvision/prototype/datasets/_builtin/usps.py,,
torchvision/prototype/datasets/_builtin/voc.categories,,
torchvision/prototype/datasets/_builtin/voc.py,,
torchvision/prototype/datasets/_folder.py,,
torchvision/prototype/datasets/_home.py,,
torchvision/prototype/datasets/benchmark.py,,
torchvision/prototype/datasets/generate_category_files.py,,
torchvision/prototype/datasets/utils/__init__.py,,
torchvision/prototype/datasets/utils/__pycache__/__init__.cpython-39.pyc,,
torchvision/prototype/datasets/utils/__pycache__/_dataset.cpython-39.pyc,,
torchvision/prototype/datasets/utils/__pycache__/_internal.cpython-39.pyc,,
torchvision/prototype/datasets/utils/__pycache__/_resource.cpython-39.pyc,,
torchvision/prototype/datasets/utils/_dataset.py,,
torchvision/prototype/datasets/utils/_internal.py,,
torchvision/prototype/datasets/utils/_resource.py,,
torchvision/prototype/features/__init__.py,,
torchvision/prototype/features/__pycache__/__init__.cpython-39.pyc,,
torchvision/prototype/features/__pycache__/_bounding_box.cpython-39.pyc,,
torchvision/prototype/features/__pycache__/_encoded.cpython-39.pyc,,
torchvision/prototype/features/__pycache__/_feature.cpython-39.pyc,,
torchvision/prototype/features/__pycache__/_image.cpython-39.pyc,,
torchvision/prototype/features/__pycache__/_label.cpython-39.pyc,,
torchvision/prototype/features/__pycache__/_mask.cpython-39.pyc,,
torchvision/prototype/features/__pycache__/_video.cpython-39.pyc,,
torchvision/prototype/features/_bounding_box.py,,
torchvision/prototype/features/_encoded.py,,
torchvision/prototype/features/_feature.py,,
torchvision/prototype/features/_image.py,,
torchvision/prototype/features/_label.py,,
torchvision/prototype/features/_mask.py,,
torchvision/prototype/features/_video.py,,
torchvision/prototype/models/__init__.py,,
torchvision/prototype/models/__pycache__/__init__.cpython-39.pyc,,
torchvision/prototype/models/depth/__init__.py,,
torchvision/prototype/models/depth/__pycache__/__init__.cpython-39.pyc,,
torchvision/prototype/models/depth/stereo/__init__.py,,
torchvision/prototype/models/depth/stereo/__pycache__/__init__.cpython-39.pyc,,
torchvision/prototype/models/depth/stereo/__pycache__/crestereo.cpython-39.pyc,,
torchvision/prototype/models/depth/stereo/__pycache__/raft_stereo.cpython-39.pyc,,
torchvision/prototype/models/depth/stereo/crestereo.py,,
torchvision/prototype/models/depth/stereo/raft_stereo.py,,
torchvision/prototype/transforms/__init__.py,,
torchvision/prototype/transforms/__pycache__/__init__.cpython-39.pyc,,
torchvision/prototype/transforms/__pycache__/_augment.cpython-39.pyc,,
torchvision/prototype/transforms/__pycache__/_auto_augment.cpython-39.pyc,,
torchvision/prototype/transforms/__pycache__/_color.cpython-39.pyc,,
torchvision/prototype/transforms/__pycache__/_container.cpython-39.pyc,,
torchvision/prototype/transforms/__pycache__/_deprecated.cpython-39.pyc,,
torchvision/prototype/transforms/__pycache__/_geometry.cpython-39.pyc,,
torchvision/prototype/transforms/__pycache__/_meta.cpython-39.pyc,,
torchvision/prototype/transforms/__pycache__/_misc.cpython-39.pyc,,
torchvision/prototype/transforms/__pycache__/_presets.cpython-39.pyc,,
torchvision/prototype/transforms/__pycache__/_temporal.cpython-39.pyc,,
torchvision/prototype/transforms/__pycache__/_transform.cpython-39.pyc,,
torchvision/prototype/transforms/__pycache__/_type_conversion.cpython-39.pyc,,
torchvision/prototype/transforms/__pycache__/_utils.cpython-39.pyc,,
torchvision/prototype/transforms/_augment.py,,
torchvision/prototype/transforms/_auto_augment.py,,
torchvision/prototype/transforms/_color.py,,
torchvision/prototype/transforms/_container.py,,
torchvision/prototype/transforms/_deprecated.py,,
torchvision/prototype/transforms/_geometry.py,,
torchvision/prototype/transforms/_meta.py,,
torchvision/prototype/transforms/_misc.py,,
torchvision/prototype/transforms/_presets.py,,
torchvision/prototype/transforms/_temporal.py,,
torchvision/prototype/transforms/_transform.py,,
torchvision/prototype/transforms/_type_conversion.py,,
torchvision/prototype/transforms/_utils.py,,
torchvision/prototype/transforms/functional/__init__.py,,
torchvision/prototype/transforms/functional/__pycache__/__init__.cpython-39.pyc,,
torchvision/prototype/transforms/functional/__pycache__/_augment.cpython-39.pyc,,
torchvision/prototype/transforms/functional/__pycache__/_color.cpython-39.pyc,,
torchvision/prototype/transforms/functional/__pycache__/_deprecated.cpython-39.pyc,,
torchvision/prototype/transforms/functional/__pycache__/_geometry.cpython-39.pyc,,
torchvision/prototype/transforms/functional/__pycache__/_meta.cpython-39.pyc,,
torchvision/prototype/transforms/functional/__pycache__/_misc.cpython-39.pyc,,
torchvision/prototype/transforms/functional/__pycache__/_temporal.cpython-39.pyc,,
torchvision/prototype/transforms/functional/__pycache__/_type_conversion.cpython-39.pyc,,
torchvision/prototype/transforms/functional/_augment.py,,
torchvision/prototype/transforms/functional/_color.py,,
torchvision/prototype/transforms/functional/_deprecated.py,,
torchvision/prototype/transforms/functional/_geometry.py,,
torchvision/prototype/transforms/functional/_meta.py,,
torchvision/prototype/transforms/functional/_misc.py,,
torchvision/prototype/transforms/functional/_temporal.py,,
torchvision/prototype/transforms/functional/_type_conversion.py,,
torchvision/prototype/utils/__init__.py,,
torchvision/prototype/utils/__pycache__/__init__.cpython-39.pyc,,
torchvision/prototype/utils/__pycache__/_internal.cpython-39.pyc,,
torchvision/prototype/utils/_internal.py,,
torchvision/transforms/__init__.py,,
torchvision/transforms/__pycache__/__init__.cpython-39.pyc,,
torchvision/transforms/__pycache__/_functional_video.cpython-39.pyc,,
torchvision/transforms/__pycache__/_pil_constants.cpython-39.pyc,,
torchvision/transforms/__pycache__/_presets.cpython-39.pyc,,
torchvision/transforms/__pycache__/_transforms_video.cpython-39.pyc,,
torchvision/transforms/__pycache__/autoaugment.cpython-39.pyc,,
torchvision/transforms/__pycache__/functional.cpython-39.pyc,,
torchvision/transforms/__pycache__/functional_pil.cpython-39.pyc,,
torchvision/transforms/__pycache__/functional_tensor.cpython-39.pyc,,
torchvision/transforms/__pycache__/transforms.cpython-39.pyc,,
torchvision/transforms/_functional_video.py,,
torchvision/transforms/_pil_constants.py,,
torchvision/transforms/_presets.py,,
torchvision/transforms/_transforms_video.py,,
torchvision/transforms/autoaugment.py,,
torchvision/transforms/functional.py,,
torchvision/transforms/functional_pil.py,,
torchvision/transforms/functional_tensor.py,,
torchvision/transforms/transforms.py,,
torchvision/utils.py,,
torchvision/version.py,,
torchvision/zlib.dll,,
torchvision\_C.pyd,sha256=lW4gM18gNOM4DII9cGCwh9XYTG6AdllcWD4pR0SqMFs,5794304
torchvision\__init__.py,sha256=IB8pEhedwOA4eh_pZ1vIWpPcR2xmtjvLhsQ1L5tmFTw,3001
torchvision\_internally_replaced_utils.py,sha256=oas5PoFR4LlsQAe4-cHj-FNsehe-deWD4AMwq4Y672U,1801
torchvision\_utils.py,sha256=kcSn6P3Vjv5QPgHHNmNu59Mh-NLb5MDlYxvDkNJWrOM,966
torchvision\cudart64_110.dll,sha256=Zb4yzggybAKbksiDb3TkDYSNH51a5KQQg4aWCOFnoM8,518144
torchvision\datasets\__init__.py,sha256=MpFFqHu8UtyyQ8JImEJqrY_bqwY3xMLiB1Xf-AR7sY8,3099
torchvision\datasets\_optical_flow.py,sha256=51j5k3ePIBHR17YOi-3UdVrOuoBS0b7AF_IA15r6Ki8,18973
torchvision\datasets\_stereo_matching.py,sha256=QLPOtwNVuc4Z4yzEeX8yFCx8GfqY7TGxRO-T2rSFr8Y,49251
torchvision\datasets\caltech.py,sha256=ZFJ-yA17AVDrG4mxZY5QcBgEf5oZX50_DzgMXd9_GMU,8975
torchvision\datasets\celeba.py,sha256=j3iBnk7xH_YFKrXIxO7ToHYdGlw2ylMvWWr4Hix8LuY,8486
torchvision\datasets\cifar.py,sha256=yP0PumJE_tFnWbo3sd_QRdiEIJCFVfwR6wimPj41OJA,5956
torchvision\datasets\cityscapes.py,sha256=eo2-rUli_dRBMmH-KSX33jik8kTpAb7lA-W8dXHsOQI,10458
torchvision\datasets\clevr.py,sha256=l2H_H4Jqmet68BqbgHehMZ65_GTLQkvGe9vRPfLNXLc,3504
torchvision\datasets\coco.py,sha256=fvHT5x62MhLG4pE8MUlpW-6g6_HEeizJjnIYZK3HxFw,4076
torchvision\datasets\country211.py,sha256=gRNjo8Nr6dlFf-FcoFTO9KeRgAqs7VC4PslbPe3BxQo,2466
torchvision\datasets\dtd.py,sha256=Tw2i_6Pm-PrRhcxrphYP1_s-YtNidqn7Y3ZUGXg6sYo,4039
torchvision\datasets\eurosat.py,sha256=qTI24oTjJVXlfs5VHjvjC_3If9s9joobS1X7mbxswII,2111
torchvision\datasets\fakedata.py,sha256=eEiZFwVkcd0Zo-eps8AMRUkUpGKj9eQDZ6hoDxqsln0,2548
torchvision\datasets\fer2013.py,sha256=tot-6jE7_y8VRmugSUhGTPWi2O7puVyZJ90-Tb4pZ7M,2837
torchvision\datasets\fgvc_aircraft.py,sha256=RjJq2qiV2kKx84vZunk_asLdhi_BYU8cxT0QxJbQ7Ps,4675
torchvision\datasets\flickr.py,sha256=2MUvshyI3BfmEHja9yao_Fq5pqK9A_mXxxjvf4o3Sb0,5505
torchvision\datasets\flowers102.py,sha256=qcFvVaO23zRWbJ55UYMHqN_lT7ZyP4YpW1sg62QS6OE,4714
torchvision\datasets\folder.py,sha256=PdB8r5mjBZC4IGrVzRcCf7zwHF0pF3RVCJF8m1SFvDI,12227
torchvision\datasets\food101.py,sha256=RGdEkso6uspy94xHDtGh_IUPkNmE05mvy9gJRt1GfXs,3805
torchvision\datasets\gtsrb.py,sha256=3MpXIXkf9NiOa3Km75dRbjlx_uUqYtt-sQIGNKzT8gE,3845
torchvision\datasets\hmdb51.py,sha256=RAGU-c8IKdYZgAFdc4_o8xKaqd6MYGzX0ckprdWKWi4,6061
torchvision\datasets\imagenet.py,sha256=cPf5Lbw0I57fBkIkk_Io9R33vaSVYatdwtob0JtFPGU,8342
torchvision\datasets\inaturalist.py,sha256=G9SROR4dKUXv7K-MrR14vXFxw0aMRMmSkkPlZIf0lfA,10348
torchvision\datasets\kinetics.py,sha256=g3DEbxUZRjQou-EYSSgWrY8Ap34G-X0m19XWVnFnlUM,10580
torchvision\datasets\kitti.py,sha256=yuX-fPZN7Rs08ZFWkOXNn9EXEng0oqO8H1rsEFcPyF0,5758
torchvision\datasets\lfw.py,sha256=RLLVKg5_MvNdPvSPELnS4uYp6LMdp8ZqODs1NDIa6M0,10537
torchvision\datasets\lsun.py,sha256=EkIlHlrmaKBLjCxKGFwYKIiYQkfsPxFWnUomGlfOchU,5842
torchvision\datasets\mnist.py,sha256=HWQKw8CvTC25i-N4rciwHzYugY27EuGacUG-qtkT2ys,21817
torchvision\datasets\omniglot.py,sha256=th4Rfpgz0b4O-3nKjwzJz4if0Xdn0oe3v1qz5gViN7w,4193
torchvision\datasets\oxford_iiit_pet.py,sha256=ny1u1p1e3ihlpMEiYxbefFZ8hcXaHV7NZ2s7XI002JM,5178
torchvision\datasets\pcam.py,sha256=XGYE-jz3C52-PaRlU0zAJYmOK7MPGxdgJXC2e28c-Ts,5245
torchvision\datasets\phototour.py,sha256=kiBA1S-06U0qWxwgG06lVFiqRpC12z-fzD_IOo1y8VA,8152
torchvision\datasets\places365.py,sha256=OOl9iQNYPqNAvgxZwqMtT-eHa-CWlPrys76GOTNnl-E,7371
torchvision\datasets\rendered_sst2.py,sha256=q4JlV-HHpHIKRXhC5ajWRUihV__lROrRFS-Yth_8C4w,3643
torchvision\datasets\samplers\__init__.py,sha256=yX8XD3h-VwTCoqF9IdQmcuGblZxvXb2EIqc5lPqXXtY,164
torchvision\datasets\samplers\clip_sampler.py,sha256=ERp9c0O3ZGQNR3lLXvZXWjfJkXayYym8bhYfOm_MNKI,6416
torchvision\datasets\sbd.py,sha256=Bl0uvVerxkh1vk5Wq11gWzo9jrERVsPThK5sxIai1X4,5325
torchvision\datasets\sbu.py,sha256=iHc4l2Map3RpbZBKFR-5Z1qyqF5FDE1fH5ipXR7vii8,4310
torchvision\datasets\semeion.py,sha256=Gsu8T1abeE0t-0lHf8TACuXh09BruHExjiw3d-bEZaQ,3179
torchvision\datasets\stanford_cars.py,sha256=-vBokYn4GHz8dvmN5GfV5teXBL1sLnYSk9MZHPV7RZI,4964
torchvision\datasets\stl10.py,sha256=KNIXNKFcM14P62UZRctpIxsKiboBWHVkyndD6sNIzGo,7406
torchvision\datasets\sun397.py,sha256=i6UOPBjpxMg33yTePwU-YOJIyud5b6sLFICbeQgc3Ho,2819
torchvision\datasets\svhn.py,sha256=BtHeau3PHCrlXwwngRC6PstHePIgf2Ga6nAKYCcSrOs,4895
torchvision\datasets\ucf101.py,sha256=tecwcnJ7GYwEWOhKRdQeUlYemH9GhY2f0miiBgsxgTo,5603
torchvision\datasets\usps.py,sha256=PyFECpMSh0sMswf-rZFpzy-Uyopa2BLMEYKLJgGWBRE,3535
torchvision\datasets\utils.py,sha256=XwTsHBTNkbp9zil9SqTA22SN-HeU6MRWE-0uirCEoeY,19143
torchvision\datasets\video_utils.py,sha256=dj92rQWaCwuugu56q8XR9EhCtniSYYPzQK_ZLqL4es0,17428
torchvision\datasets\vision.py,sha256=4zp2Jbnm0xdlkmyKQd3q9NVL6TQIuqEY7EVDVYNjHCo,4281
torchvision\datasets\voc.py,sha256=QFt-ALxLyeSFi-pNM191DOt5HKQz5ET_MHGTyyddlgU,8984
torchvision\datasets\widerface.py,sha256=KQT3n9YcJkkmdYDln-JRHUSYP8t-Bvp5Bp6qs1_b8-A,8252
torchvision\extension.py,sha256=adOpOZpSCHuTrbDpipwPFR9JLoa_2fWOZRhNafpitR8,4021
torchvision\image.pyd,sha256=0N-t4AdselgIBlKxcfQr1TinZwUzS3sZ8ow5Gs6M1wI,357376
torchvision\io\__init__.py,sha256=nz1TE-9QnICffLEoaKhOgLOmooyyiAK2rWJaDqexvWU,1545
torchvision\io\_load_gpu_decoder.py,sha256=B3mPLXerJYXqiHv9FO2laRrGRlIkXii7CsD0J8J_SwU,182
torchvision\io\_video_opt.py,sha256=qDF-XL8Ezf0aaIWgHUpRFQUWqnYfL6A9WKYvztV_uLE,20234
torchvision\io\image.py,sha256=KGIPIb9Of9HTV_Jpifzfxp93x5TAGREdQtX5SjCG13s,9833
torchvision\io\video.py,sha256=5vVhtfcAihw5GfYvyxT9UVQ8CPq_u0H81KT4_MUxB98,16103
torchvision\io\video_reader.py,sha256=UkX_mbIjSxD1iVT2p6y3tQyrU5psPvCn2d016VPREy8,8220
torchvision\libjpeg.dll,sha256=RqPZ7l_awQdV8gwNfq4uF6qso45ravyjVQPBb8IOd_I,229376
torchvision\libpng16.dll,sha256=rsn_UBkP5HAfaNf4cN4KKTxtp6fZ_eQfH_HTODlTN9s,192512
torchvision\models\__init__.py,sha256=_XXIQtTEOrrNJuoFQGWOvAdopXSeH0_o_sWq8CZydaE,584
torchvision\models\_api.py,sha256=WeDu9X2h0fj9NMfa8zClGpUJCUAIiUs5Kpy9rC8kcAg,7995
torchvision\models\_meta.py,sha256=2NSIICoq4MDzPZc00DlGJTgHOCwTBSObSTeRTh3E0tQ,30429
torchvision\models\_utils.py,sha256=ODq0KHP2nhO-X0j3S6yMLPf0DBX2Tyh8sKO_r6lLafU,11151
torchvision\models\alexnet.py,sha256=MEPgmJulAut92NngZ8H9s5kESygKLfKwPIvn39D1Bm4,4751
torchvision\models\convnext.py,sha256=tOQYWCC9lBhjShGVZoMXMIQQEHUUs2bHAyGuR7CnvnE,15465
torchvision\models\densenet.py,sha256=SNqXvMoJThJFsj2XxHzLMDCzCfz0B0Wi6Q9Y4kqle_k,17407
torchvision\models\detection\__init__.py,sha256=D4cs338Z4BQn5TgX2IKuJC9TD2rtw2svUDZlALR-lwI,175
torchvision\models\detection\_utils.py,sha256=gjJx_THX7vKE8M80L6eYavneRZEbVpWGhJ8_UL0DDno,22823
torchvision\models\detection\anchor_utils.py,sha256=sBZq3j-rK6iOf-vX0isc7OTLv96UDK-ugjhZYp2Cozw,12126
torchvision\models\detection\backbone_utils.py,sha256=QAUh5McrpKL4zK4oaG5drliDe8cdg0Mb7hVqdeH1FWA,10706
torchvision\models\detection\faster_rcnn.py,sha256=KTxzhe3dcfdAUYckOQYPTs22qlXQwkZmGEfHIbJOM3c,37790
torchvision\models\detection\fcos.py,sha256=7nHpudycD2RMmGJPIIk9xq-JHXGsk3nVDrkMSMBwZOo,34935
torchvision\models\detection\generalized_rcnn.py,sha256=nLVj2o8yr6BW1MN12u30QuFbvtsdllEbUlbNH-dO-G0,4861
torchvision\models\detection\image_list.py,sha256=IzFjxIaMdyFas1IHPBgAuBK3iYJOert5HzGurYJitNk,808
torchvision\models\detection\keypoint_rcnn.py,sha256=3MowCitrPDWE-Z5qKdwWxsZZ5FUS1ajAUSojjsvxN2Y,22548
torchvision\models\detection\mask_rcnn.py,sha256=8nKVHRhHijFMNNCjuXAUvug-ztQVDt60C0ArxMk4mPo,27189
torchvision\models\detection\retinanet.py,sha256=bzDSAv5SkO1w-a5k3wEMxt5L9vpaMaMwuuccxapMmD8,38057
torchvision\models\detection\roi_heads.py,sha256=-Dv2rGPNjkvK3D1nuQIajJNYC4utssagkgZS8qoFnPQ,34698
torchvision\models\detection\rpn.py,sha256=zQ4S0EchqmRPVUDAoKQV3O4gK2b-n-AlwyihEp6yikE,16122
torchvision\models\detection\ssd.py,sha256=wqQeipHS7X5JnJSvglKRnTSO4Qmfq37_amb2rCZ5yLg,30316
torchvision\models\detection\ssdlite.py,sha256=25bhyxm6APKv4FpCWf76tbqPi86tC9hfDc78v8wtkbs,13734
torchvision\models\detection\transform.py,sha256=Rp6_b91xPf_07lRQ_6ihCwLlpHn-vMlNrHhuILJOLYo,12148
torchvision\models\efficientnet.py,sha256=3Xk2GT01oI9v5T0tReJtpWl36IkZzm4BoPaoFU0igic,44246
torchvision\models\feature_extraction.py,sha256=FWecF9xli71GslLbZXN8hAgXWMrXiw0KVjrXO-9TsmM,26134
torchvision\models\googlenet.py,sha256=dqZDSQpcMJjygmg4f3FXrETrg53urt5XA5L40aeIfFs,13344
torchvision\models\inception.py,sha256=VH1D7i140r7vY6gc8YT4zpYx924EL22xyR1DVGjLoSo,19537
torchvision\models\maxvit.py,sha256=MqYzdNOPdegim1pLoKuyJu55ohZXqM--yrBTULiYYP0,32707
torchvision\models\mnasnet.py,sha256=XmTKB-UVaH05SO-b-4JIACAZkLBbfLuRgGOkb5a-I-o,17759
torchvision\models\mobilenet.py,sha256=alrEJwktmXVcCphU8h2EAJZX0YdKfcz4tJEOdG2BXB8,217
torchvision\models\mobilenetv2.py,sha256=kXaHSuQs23F8VdT3s94TouY3fRWuAzK28KQ-Jd42Fqk,10061
torchvision\models\mobilenetv3.py,sha256=Gm0ewkUnA38D7r7-Q4HDEaO602MfEo96W7bNiNl4xF8,16815
torchvision\models\optical_flow\__init__.py,sha256=uuRFAdvcDobdAbY2VmxEZ7_CLH_f5-JRkCSuJRkj4RY,21
torchvision\models\optical_flow\_utils.py,sha256=PRcuU-IB6EL3hAOLiyC5q-NBzlvIKfhSF_BMplHbzfY,2125
torchvision\models\optical_flow\raft.py,sha256=ob_phasLa79MVEGhDmANOaE-OjoVNSjK9Fhe-ZvWSQ8,39569
torchvision\models\quantization\__init__.py,sha256=YOJmYqWQTfP5P2ypteZNKQOMW4VEB2WHJlYoSlSaL1Y,130
torchvision\models\quantization\googlenet.py,sha256=EYXeWcMDSYt3UKCYWK_THw_uIEcFUTxCfKXZRZtllEk,8603
torchvision\models\quantization\inception.py,sha256=UqQQQ8E2PYKRGDZ34sWDW6EV7M1TtMDDL08lQCIMW4o,11399
torchvision\models\quantization\mobilenet.py,sha256=alrEJwktmXVcCphU8h2EAJZX0YdKfcz4tJEOdG2BXB8,217
torchvision\models\quantization\mobilenetv2.py,sha256=woL647evmNNaJI1so75CC9QUO1Qx4h3KHCIc5UxTgzU,6277
torchvision\models\quantization\mobilenetv3.py,sha256=BEYSqVw3ca1YYu4pLLGhKSs8cdXobuCeZKCxxiR-Lcc,9718
torchvision\models\quantization\resnet.py,sha256=5jpNzbN4K6Bp-GaIcRlokpj7qtt9t5odCKA2HsKiZH4,18506
torchvision\models\quantization\shufflenetv2.py,sha256=ogOD1HtnjHFqOKO9kUnAZDSzPD17K39c4ULq_QgQ9DI,17475
torchvision\models\quantization\utils.py,sha256=Ij88l6toyO8MQi1w512Jt-yQ2Q9hK75-Z2SOjIzS6Zw,2109
torchvision\models\regnet.py,sha256=G_9QpWGcocoLUCaVH1NLChgOGapX3929E_On_Ge4D-s,64060
torchvision\models\resnet.py,sha256=qzo49ZPhDOyv1Ju_zpXGrwN56Zx_v7U-sudEA_Kv_vc,39581
torchvision\models\segmentation\__init__.py,sha256=TLL2SSmqE08HLiv_yyIWyIyrvf2xaOsZi0muDv_Y5Vc,69
torchvision\models\segmentation\_utils.py,sha256=yFeyBa5_Pyv1UQ_2N64XMRgTYsxifwzDd-VRP-vmIGM,1234
torchvision\models\segmentation\deeplabv3.py,sha256=JTS9wv49wGOLGIDYrmfAuezbmduGXAj4--GryuZ8kN8,15575
torchvision\models\segmentation\fcn.py,sha256=MOsqmno54y0_4GuzvtJ5uzjI6a7FnqVGAdxw9ZJ-bYw,9372
torchvision\models\segmentation\lraspp.py,sha256=WScq_PF7j3Uu1X-do52DQdi8aKz48jL0CmnKbSiUBO4,8019
torchvision\models\shufflenetv2.py,sha256=mFCdI2csy159qA0xEwAs7xngZS9K4EC7ez0wOFo7Ajk,15970
torchvision\models\squeezenet.py,sha256=RIqfF7gM-HH06IbL9sUcnz5tyj_R7dA4DeKBcTXJI7A,9149
torchvision\models\swin_transformer.py,sha256=G_ssDp1Nm4mJttfsEkpyY6I4hbekDG54X4gOPb228IQ,39558
torchvision\models\vgg.py,sha256=lSQ080Swgytidv80JN_Iafm92KY7ASWDpDaGrjgeNQ0,19743
torchvision\models\video\__init__.py,sha256=wfzX0NargzHO9m6OghAz33GDWWe7kmbL5IS0bOh-tEU,64
torchvision\models\video\mvit.py,sha256=ceQiV3K9sgKUMNG3WK5iJxZnwT4k_W7v2Yb9Ew8wEo0,33616
torchvision\models\video\resnet.py,sha256=U2x6VcKjFarqQmhDrJJVq2dgaXADamcLWlf044iCmYU,17063
torchvision\models\video\s3d.py,sha256=HNmT2ddGEJFPDyQqcUk46tj8yAkjqtdFCMm6asOqobo,7953
torchvision\models\vision_transformer.py,sha256=nR9FPI3Wrgbx8uSnmtXHDGaI2N22JvmH7nmwZ6v4j7U,32739
torchvision\nvjpeg64_11.dll,sha256=za4V7Pyv2DP9btPClB6-x0ug_rj70DYWUlsKJhbEVtU,3706368
torchvision\ops\__init__.py,sha256=7wibGxcF1JHDviSNs9O9Pwlc8dhMSFfZo0wzVjTFnAY,2001
torchvision\ops\_box_convert.py,sha256=U0iPo5GpCvo8FGcnPwYIYw0upoEM_omm1CknBT4L0mo,2489
torchvision\ops\_register_onnx_ops.py,sha256=cAyMiAwQnvrpGD-IotzcVsSKIiZCcIJtUIbK5tlTePA,4250
torchvision\ops\_utils.py,sha256=xFrLnLhKDHiG2TN39tUWY-MJbLEPka6dkaVVJFAN7-8,3736
torchvision\ops\boxes.py,sha256=LtwFsa6GDIs4nSxSIpQ48sza1ucvJGfQCHmreSoul5s,15912
torchvision\ops\ciou_loss.py,sha256=Qzm89C82ehX-YvYBPLPRPhbJZdr3itizxuxrT7MLi9o,2834
torchvision\ops\deform_conv.py,sha256=HJOCXx088QJkPz442otgznhwaOkPBdbc9f5h0u1hPWk,7185
torchvision\ops\diou_loss.py,sha256=Z2dTeYGyCxUVO06BLZ3OVlVSsj_ybX0R65sAPjpLhXg,3456
torchvision\ops\drop_block.py,sha256=ZkIzM1b3v5_U7z0eavzaNpN7IBq0N4ZNwwvWArispwg,6010
torchvision\ops\feature_pyramid_network.py,sha256=5mrWAaKzsioSVX888Q7JllNXCS7sHuvVvmaLw-ntqe0,8818
torchvision\ops\focal_loss.py,sha256=lS5FqgLFuDKlpm0sk5V1VgIA6LFAdJUXQaPi35nEDoU,2319
torchvision\ops\giou_loss.py,sha256=QSgsLvSmY1dXRVxk8rTjpN6wwdS9J_1Bl6-HGGymIXg,2772
torchvision\ops\misc.py,sha256=8V6m6nQYnPe4ckir4ZQ-FYVleCDAKvgvPbvIP4exDEI,13768
torchvision\ops\poolers.py,sha256=dkSci5y0PB83STVaDp6gOBqG95W7qXdhTBwSbhM-29o,12245
torchvision\ops\ps_roi_align.py,sha256=6_kmnE6z_3AZZ1N2hrS_uK3cbuzqZhjdM2rC50mfYUo,3715
torchvision\ops\ps_roi_pool.py,sha256=2JrjJwzVtEeEg0BebkCnGfq4xEDwMCD-Xh915mvNcyI,2940
torchvision\ops\roi_align.py,sha256=KNIJDirpCRM_hO-XNKURSTMqhSJlBuYc9rP4IltyKQY,4278
torchvision\ops\roi_pool.py,sha256=cN7rSCQfpUzETvP8SjPDl1yfXjbxg9I-tXnHbvAKya8,3015
torchvision\ops\stochastic_depth.py,sha256=9T4Zu_BaemKZafSmRwrPCVr5aaGH8tmzlsQAZO-1_-Y,2302
torchvision\prototype\__init__.py,sha256=AMZfGGnDRslc-nAFc9RujPNFkOyCmvnbgMbdug8fj4M,61
torchvision\prototype\datasets\__init__.py,sha256=AhYIQPi2NKyYAXPNRdSUPqQgbLxXRERh52sV60UFm_A,647
torchvision\prototype\datasets\_api.py,sha256=hPbErbWvryAg-PLjB-O14Q9Poa1aPPUj8ogGmW5BzI0,1828
torchvision\prototype\datasets\_builtin\__init__.py,sha256=NYHJ0f09xIso6BwzIypEVzyESHPK8bn9YcaZ8Qs9CAc,690
torchvision\prototype\datasets\_builtin\caltech.py,sha256=2gIs4BGi0RFPDjLP32QwKszlq14_9rCOPpt2rrbdljc,7023
torchvision\prototype\datasets\_builtin\caltech101.categories,sha256=uC6hl4Cy3lOt_ZQhvB6FVi3G3eg5tk72ftdb8ST_Yqc,989
torchvision\prototype\datasets\_builtin\caltech256.categories,sha256=r4KdwVr7FZuvuTUSyck4kIYHVTnceEbT8iUFlxpn5dA,2878
torchvision\prototype\datasets\_builtin\celeba.py,sha256=6YqXi4a33nqDeYbfPImQDFfZ3DhxuJS9Iaaa67InEiA,7179
torchvision\prototype\datasets\_builtin\cifar.py,sha256=z9got34ZJRJQBiyLykbuA22le77O8PRM7vrwOcbZQWU,4699
torchvision\prototype\datasets\_builtin\cifar10.categories,sha256=633jy9l275PzAFvCiq5iBseI102D2cYeslJqYabu72s,70
torchvision\prototype\datasets\_builtin\cifar100.categories,sha256=RDiXgAUi02RW4zCR_yqD27Q1vn9PenrG9B0mSav6GbI,825
torchvision\prototype\datasets\_builtin\clevr.py,sha256=lis5Zuj6Rc9HEnZpbtFV_-VPwbnRyNa-nNwKC1gAIsI,3704
torchvision\prototype\datasets\_builtin\coco.categories,sha256=w7x2InmPfwq_K8nSTbMrOPjkpEFr_T8m5nAwhgkA390,1443
torchvision\prototype\datasets\_builtin\coco.py,sha256=sodpcao4w0KJsR3jtODYSHQhxAgQlkAvhsUVoFF_dkM,10391
torchvision\prototype\datasets\_builtin\country211.categories,sha256=I8cKMrlZ_qdH8NI6_T5qkay1XkAGI_G1tui5l-_xqoE,844
torchvision\prototype\datasets\_builtin\country211.py,sha256=6TvIgikN2lq1LvGTTpSqpUwGsa0yQThxqk0zL_5T6uc,2738
torchvision\prototype\datasets\_builtin\cub200.categories,sha256=f5qFtq_FWoFUXY6Zs9q7aBaJxvChO1hDVpWuKEB08q0,3532
torchvision\prototype\datasets\_builtin\cub200.py,sha256=T_yGuTmMTbiqjTCjhHzU0PQrdMrPtt6NYiAxlJynGU8,9533
torchvision\prototype\datasets\_builtin\dtd.categories,sha256=Q6anHvqMxN1qv05DUEkiVhxGD6-d5GPXYjkRJD2ZCLc,441
torchvision\prototype\datasets\_builtin\dtd.py,sha256=RR--2lK-kKtp9gfOlUCnEpVIPB8gV-QjjbtWek_-01I,4781
torchvision\prototype\datasets\_builtin\eurosat.py,sha256=4H04PPWkXG3yaXSyuq0ZLBXaCIfl1XXZsBxTnDRT68E,2116
torchvision\prototype\datasets\_builtin\fer2013.py,sha256=K18ojG01KKRhIf0iV6BnxvveWEduiWbTr-j-URz_LPA,2468
torchvision\prototype\datasets\_builtin\food101.categories,sha256=sUMSYDA10YVLxyghp8cDvvQvWvlM7m1x5Dl3Jyz6TKA,1285
torchvision\prototype\datasets\_builtin\food101.py,sha256=zGC6YM5_dN9-8Iwfye3pQ0MYNnNex42kxYYiS_Eh3UE,3515
torchvision\prototype\datasets\_builtin\gtsrb.py,sha256=hfe4xcSKwYywB9hvuJJVegHlnDihQvxYp_9QwxHMCa8,4124
torchvision\prototype\datasets\_builtin\imagenet.categories,sha256=teq2DhM4XaYFhDfdcmmgqG5qZvLuhFQIYZieJyUE54Y,21488
torchvision\prototype\datasets\_builtin\imagenet.py,sha256=bpXAP3wgeoOkNnh4jMq_xf33EOSYFTt7FDOQS8jSqnk,8312
torchvision\prototype\datasets\_builtin\mnist.py,sha256=2k4798L4MqBQFpZ8fRRQ4AkDY5_STUdd0PKvvHXk-8s,15449
torchvision\prototype\datasets\_builtin\oxford-iiit-pet.categories,sha256=NCtfnYuhQPSkvUNVJKbEo7ClkpG7kiKrYxsqtf3TYU0,506
torchvision\prototype\datasets\_builtin\oxford_iiit_pet.py,sha256=sx_5TNSC7l5EocHRPFpIfRod1ZRKDjtN0Kytx7T1b24,5789
torchvision\prototype\datasets\_builtin\pcam.py,sha256=NxPqHLko_Lv3KAWYixlczzeCFG56KOq8UhiDDnL0ymo,4842
torchvision\prototype\datasets\_builtin\sbd.categories,sha256=gj_P20X71AJGFCtrBAcWXkkf3aTTmgGIPi7onwwnNOA,155
torchvision\prototype\datasets\_builtin\sbd.py,sha256=srDGhRANX-wS777KfPastnohNvI0dki6QAm8qCauy-c,5810
torchvision\prototype\datasets\_builtin\semeion.py,sha256=CNoXpXgDKjfzDk-PTf-rDh-qFIif1NZcjphG3KIOGoc,2003
torchvision\prototype\datasets\_builtin\stanford-cars.categories,sha256=ggt3mAwzYy2emjSNCStkO11zXQxoxprEOvyZxf4rYiA,5650
torchvision\prototype\datasets\_builtin\stanford_cars.py,sha256=QxUoVP7Q28CyDli1imY4eSnHXwLfYdPRgbJsGfq2Brg,4475
torchvision\prototype\datasets\_builtin\svhn.py,sha256=xmwDRaNcoq3jOGSEdkE1ZdO1Yh9yqB9nq8cGrJzkpCk,2840
torchvision\prototype\datasets\_builtin\usps.py,sha256=f58Ff7CSsUDIEs4bz_0Oe8MHK4r9QQfzrwUP5KsLLD0,2452
torchvision\prototype\datasets\_builtin\voc.categories,sha256=M_QJwWCMr3OOawdB-AmVUuPTaOTGTRyceSwmc8aWc8Y,171
torchvision\prototype\datasets\_builtin\voc.py,sha256=YJIEIHx0aPHGGuOER0zGQXU__0l_4vmcWOwALk8h-HA,9505
torchvision\prototype\datasets\_folder.py,sha256=oaHQnM6-TuK15gTdDxX4IZ6ZV7babYNslcmiyfDDlSc,2507
torchvision\prototype\datasets\_home.py,sha256=2IZz9Q2lGeHVLRphTLp-JDRqUyiIg9IGggFl77rBTRg,676
torchvision\prototype\datasets\benchmark.py,sha256=4e5i1p0SnHmTXEcElBjLFXSND9236CnKqZCRzYkhE1U,22221
torchvision\prototype\datasets\generate_category_files.py,sha256=AcqhyQkLNoa1l0s_C-fzxaTMLADSlo7Y66ibNoUPwJA,1677
torchvision\prototype\datasets\utils\__init__.py,sha256=Yz1Z8DVx-f5k3JZbQeDOMOwy0wuhaDw1Q4KbXNNxC-0,188
torchvision\prototype\datasets\utils\_dataset.py,sha256=7NDJXnkkgN_MvnG2PDbiU2Zh2leBmLyA9-XV-Y56Aso,1968
torchvision\prototype\datasets\utils\_internal.py,sha256=dVLgSmIPkdpdEuW8kGNt_yVeHzX7Ikkhoxi7vxhf1Ng,6757
torchvision\prototype\datasets\utils\_resource.py,sha256=ReE1PKdlJzA7t8MroFHYUkmIztdWUkFvoZj6kc2oFbw,8641
torchvision\prototype\features\__init__.py,sha256=MNizCyXB98gSYvQQXP3Uaz4P1cd2a_CJlK0FRmoeDq8,461
torchvision\prototype\features\_bounding_box.py,sha256=0Xrx7GoArVbfi5EfBAzg4PD8YcJGnj5mQp_SyWjrTL0,6894
torchvision\prototype\features\_encoded.py,sha256=XYERNueKdBPOPR6on5rrKLGn4Uy7ApDtyEqywIlrkuE,1915
torchvision\prototype\features\_feature.py,sha256=ktJb5WoB49W0yzsu9snNZP_8JZ3qfcLYwkvay8osdds,10679
torchvision\prototype\features\_image.py,sha256=L7xdax2SbGuRvXIyl7phEnLBmFmTi_vK8jCJsk2M9mU,10482
torchvision\prototype\features\_label.py,sha256=bXLTXaVIgpKyg2VY99IEvATH4UR7feuDfUGLNK95hqc,2403
torchvision\prototype\features\_mask.py,sha256=VdRaKbTWGoQsYYWdwbVehWLQA8-BWj8xOXqo66YDxNI,4616
torchvision\prototype\features\_video.py,sha256=hK50HESqSI5mj2zp3_Z7cWQtmwe-PRctaQK05uqR7WI,9094
torchvision\prototype\models\__init__.py,sha256=ZcKkotg_rCpLiY1iH4yWCfgF4pVoqC1eT8oUenuXCcQ,21
torchvision\prototype\models\depth\__init__.py,sha256=Zohl1Dy0JyCwHmGz10iqljPuNmuhjGcerB3KN4HLiIw,22
torchvision\prototype\models\depth\stereo\__init__.py,sha256=FbuL-euu3pNVLmRWrwdAdDn0Cw9wPhVa6cE3bLv75oU,54
torchvision\prototype\models\depth\stereo\crestereo.py,sha256=emqoTIyJhLMYAmZcdy86RgwsCH-KZtfzY0Xoc_tqo00,66098
torchvision\prototype\models\depth\stereo\raft_stereo.py,sha256=2iHmaMnUNA8UIPV29npTlxZQbcD_OqpnH6TnCYF1C70,37591
torchvision\prototype\transforms\__init__.py,sha256=UUv8_qB0mEUhbNQqZ_LB2MRugQPuYe8rZjSSb4h3et0,1650
torchvision\prototype\transforms\_augment.py,sha256=2mX0bRbbF7DUdLU-C4Meyv6iG-YItLLe7PRNAp84KsA,16436
torchvision\prototype\transforms\_auto_augment.py,sha256=6DiP4vk3NIIUwZnmDOUAIrgDqjzMdPqMeKZIOeZ1Tak,26200
torchvision\prototype\transforms\_color.py,sha256=LOp8mNxmJqlVhp0-T_NYDYficY9iXh_nkklztQCY1_I,8289
torchvision\prototype\transforms\_container.py,sha256=NOrsVsH8H8-j7_LViULN9AT6h7D2ZrD5tEWTxZDf7XI,3263
torchvision\prototype\transforms\_deprecated.py,sha256=etQeALhu8zHOYSLqUhWH4-0r2fftZGqbYGhho8LgohY,4017
torchvision\prototype\transforms\_geometry.py,sha256=8DlNmtUMjxSCxg98VZOtht9pfbHTUsSBbj8W-eMwEoY,34837
torchvision\prototype\transforms\_meta.py,sha256=_ogoCS2HsfWWgwEycyugy5g6QX91XAed0lg8-CdG9HU,3341
torchvision\prototype\transforms\_misc.py,sha256=SVluDs6nwsySNvSVVQioH9Ld_t-LXWNNNY7dpQU1fRs,8946
torchvision\prototype\transforms\_presets.py,sha256=fcknrQlUDD6k0DH9WWLxzVKOaa5YLD5wvKXNBLY1alc,2838
torchvision\prototype\transforms\_temporal.py,sha256=2_1j1ITS4O1-1UG-2JnlTmJvutu6V60PRELbL0BOb7c,648
torchvision\prototype\transforms\_transform.py,sha256=cAdlM_mqQ2wYiNIbg0NyF7lPg2oMEg67WAnC2xVpXBM,3039
torchvision\prototype\transforms\_type_conversion.py,sha256=Xn-dTGV-ZPq7C5lf_A2RD_vNna1nXzVwjHqQ2NdgYY4,2451
torchvision\prototype\transforms\_utils.py,sha256=uj6jpgvdd7ukHEbodntw8uOAoa7ZiAOngjd4k4jBnvM,5642
torchvision\prototype\transforms\functional\__init__.py,sha256=_Vhmk2RCnNIHfJ3agtQpw-cYu7Y65-3Z6xjO_yAtE_4,4686
torchvision\prototype\transforms\functional\_augment.py,sha256=Ve8OSIIrdj_49iXnlJt8vPZhXaOBWMBXoUpB_yA9HLU,1840
torchvision\prototype\transforms\functional\_color.py,sha256=-ep7DspfyeU-rsUlaUzFNuZ_Zqu_juTG3YhRn3l4uUo,20188
torchvision\prototype\transforms\functional\_deprecated.py,sha256=J726TN9MZgqxYUo9XqakWPyszisdGnsJ44m79RoWeVU,2883
torchvision\prototype\transforms\functional\_geometry.py,sha256=TBsd8wsWBmm7nf4HSoJX5YR51Cx61ylcIumnpcPdWOg,54960
torchvision\prototype\transforms\functional\_meta.py,sha256=RsfFXQPU2dVP2KkDeFewZ_zXTIwLf8u2I74Iiorg9gE,16403
torchvision\prototype\transforms\functional\_misc.py,sha256=WhbMiM5sN0X2OOAcEOw1sShUfce-sygCg1-mO7AAdYY,6524
torchvision\prototype\transforms\functional\_temporal.py,sha256=1w-TH1EeNG7G8opUiBXZ-ysN-Fp7CT6aH8pLAGl-Ktk,1237
torchvision\prototype\transforms\functional\_type_conversion.py,sha256=xo4PgrCZwDRhyvs2niK7SuyClKjGhn4_4c9fkU6wS70,1664
torchvision\prototype\utils\__init__.py,sha256=rAgUfIBL0ZdJTgtLuS0RQA0rArO8xTaOSmav8qe_PhQ,25
torchvision\prototype\utils\_internal.py,sha256=3WtOxUHVuT1dk7QWEG20uwx2akUeby90EsjMnhSHd6w,5381
torchvision\transforms\__init__.py,sha256=WCNXTJUbJ1h7YaN9UfrBSvt--ST2PAV4sLICbTS-L5A,55
torchvision\transforms\_functional_video.py,sha256=c4BbUi3Y2LvskozFdy619piLBd5acsjxgogYAXmY5P8,3971
torchvision\transforms\_pil_constants.py,sha256=7RfwV0qVB0xSjOKKYGwl7TR2OwUdLilKO6TJI6G4M9A,843
torchvision\transforms\_presets.py,sha256=t1xDgGBoJZc8UoDAITIWFUQlpnPyftRSybDYpvuCOJs,8221
torchvision\transforms\_transforms_video.py,sha256=kbqh3mbhpU8Lrz57D9UVBEOnG2P2FU2W3gRrjTxK_nw,5123
torchvision\transforms\autoaugment.py,sha256=UD8UBlT4dWCIQaNDUDQBtc0osMHHPQluLr7seZJr4cY,28858
torchvision\transforms\functional.py,sha256=VC0Zs6mTiPszO75Qfhk0Gjn0CgSy3H8jWPxUjp3i_hI,69146
torchvision\transforms\functional_pil.py,sha256=dw15tg0taO4ar9ySbo2HE7qC9cXKIcoSPvoq2JdUZh4,12541
torchvision\transforms\functional_tensor.py,sha256=Hk7zINaRlcjYatsWqCpSxCgnjl5EGR4WWvWv6J9OR34,34811
torchvision\transforms\transforms.py,sha256=Tl8XnwfX1IZc7qkVt0c6snsgAc0hr9r58js-As9tP2Y,87893
torchvision\utils.py,sha256=IkJGWTb1lfwNf7J1frjoDXtad8PAmd2sNBF6CQB2klc,23133
torchvision\version.py,sha256=DNPtw8FjaBXNYWskbJXtWe4d4KDj9UzPgXindMbkuGY,220
torchvision\zlib.dll,sha256=VMdV5rkEmaXvSaZc6UclNShv5Ns1ZaBsSlP4pIM1Mtw,87552
